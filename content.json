{"pages":[{"title":"404","text":"","path":"404/index.html","date":"05-07","excerpt":""},{"title":"about","text":"关于我– 2020-11-26 马上要成为一只社畜的计算机菜鸡，希望能在这里记录成长。","path":"about/index.html","date":"07-17","excerpt":""},{"title":"categories","text":"","path":"categories/index.html","date":"07-17","excerpt":""},{"title":"search","text":"","path":"search/index.html","date":"05-07","excerpt":""},{"title":"tags","text":"","path":"tags/index.html","date":"07-17","excerpt":""}],"posts":[{"title":"TIDB源码学习-DDL-CreateColumn时不同状态对Insert语句的影响","text":"Add Column会schema会经历none, delete-only, write-only, write-reorganization, public五个状态 当运行insert语句时，只有处于public状态的节点才会执行成功，其他状态的节点都会无法找到该列。 原因如下： insert语句经过parse, 会由ExecuetStmt()-&gt;Compile()-&gt;Optimize()-&gt;optimize()-&gt;build()中的planBuilder.buildInsert()生成查询计划。 对于INSERT … VALUES … 会进入buildValuesListOfInsert()中： 12345678910111213141516171819202122232425func (b *PlanBuilder) buildInsert(ctx context.Context, insert *ast.InsertStmt) (Plan, error) &#123;...if len(insert.Setlist) &gt; 0 &#123; // Branch for `INSERT ... SET ...`. err := b.buildSetValuesOfInsert(ctx, insert, insertPlan, mockTablePlan, checkRefColumn) if err != nil &#123; return nil, err &#125; &#125; else if len(insert.Lists) &gt; 0 &#123; // Branch for `INSERT ... VALUES ...`. err := b.buildValuesListOfInsert(ctx, insert, insertPlan, mockTablePlan, checkRefColumn) if err != nil &#123; return nil, err &#125; &#125; else &#123; // Branch for `INSERT ... SELECT ...`. err := b.buildSelectPlanOfInsert(ctx, insert, insertPlan) if err != nil &#123; return nil, err &#125; &#125;...&#125; 在buildValuesListOfInsert()中会由PlanBuilder.getAffectCols()确定实际要插入的列。 12345func (b *PlanBuilder) buildValuesListOfInsert(ctx context.Context, insert *ast.InsertStmt, insertPlan *Insert, mockTablePlan *LogicalTableDual, checkRefColumn func(n ast.Node) ast.Node) error &#123; affectedValuesCols, err := b.getAffectCols(insert, insertPlan)...&#125; planbuilder.go:2415:getAffectCols():12345678910111213141516171819202122func (b *PlanBuilder) getAffectCols(insertStmt *ast.InsertStmt, insertPlan *Insert) (affectedValuesCols []*table.Column, err error) &#123; if len(insertStmt.Columns) &gt; 0 &#123; // This branch is for the following scenarios: // 1. `INSERT INTO tbl_name (col_name [, col_name] ...) &#123;VALUES | VALUE&#125; (value_list) [, (value_list)] ...`, // 2. `INSERT INTO tbl_name (col_name [, col_name] ...) SELECT ...`. colName := make([]string, 0, len(insertStmt.Columns)) for _, col := range insertStmt.Columns &#123; colName = append(colName, col.Name.O) &#125; var missingColName string affectedValuesCols, missingColName = table.FindCols(insertPlan.Table.VisibleCols(), colName, insertPlan.Table.Meta().PKIsHandle) if missingColName != \"\" &#123; return nil, ErrUnknownColumn.GenWithStackByArgs(missingColName, clauseMsg[fieldList]) &#125; &#125; else if len(insertStmt.Setlist) == 0 &#123; // This branch is for the following scenarios: // 1. `INSERT INTO tbl_name &#123;VALUES | VALUE&#125; (value_list) [, (value_list)] ...`, // 2. `INSERT INTO tbl_name SELECT ...`. affectedValuesCols = insertPlan.Table.VisibleCols() &#125; return affectedValuesCols, nil&#125; 在确立AffectCols时是依据table的VisibleCols来确定的： 123456789101112131415161718192021// VisibleCols implements table.Table VisibleCols interface.func (t *TableCommon) VisibleCols() []*table.Column &#123; if len(t.VisibleColumns) &gt; 0 &#123; return t.VisibleColumns &#125; return t.getCols(visible)&#125;func (t *TableCommon) getCols(mode getColsMode) []*table.Column &#123; columns := make([]*table.Column, 0, len(t.Columns)) for _, col := range t.Columns &#123; if col.State != model.StatePublic &#123; continue &#125; if (mode == visible &amp;&amp; col.Hidden) || (mode == hidden &amp;&amp; !col.Hidden) &#123; continue &#125; columns = append(columns, col) &#125; return columns&#125; 根据代码中的判断条件，如果列的状态不为StatePublic，那么就不会被归结为VisibleCols(), 也就不会被getAffectCols()所感知，Inser这一列的操作自然会报错。","path":"2020/12/01/TIDB源码学习笔记-DDL-CreateColumn时不同状态对Insert语句的影响/","date":"12-01","excerpt":"","tags":[{"name":"TIDB","slug":"TIDB","permalink":"https://haxisnake.github.io/tags/TIDB/"},{"name":"Golang","slug":"Golang","permalink":"https://haxisnake.github.io/tags/Golang/"}]},{"title":"TIDB源码学习笔记-Key编码后的比较","text":"key经过编码之后是字节数组，两个字节数组的比较方案如下所示： 判断两个字节数组的地址是否一样，如果一样则说明在同一段内存存储，直接判断长度，长度小的key编码较小。 如果首地址不一样，则按照两个数组的较小长度逐个元素比较，如有不同直接按照元素大小返回。 当在较小长度内所有元素都相同，则较大长度字节数组大于较小长度数组。如果两者长度相同且所有元素相同，则数组大小相同。 example例如有如下两个表： table1, tableId为1, 第三列value含有索引，indexID为11234rowid, name, role, value1, \"TiDB\", \"SQL Layer\", 102, \"TiKV\", \"KV Engine\", 203, \"PD\", \"Manager\", 30 table2, tableId为2, 第二列到第四列都含有索引，indexID从1到41234rowid, name, school, age, graduate date, personID(unique)1, \"XiaoMing\", \"A\", 19, 2020-06-20, 2102832, \"XiaoHong\", \"C\", 19, 2019-03-20, 2704473, \"XiaoWang\", \"B\", 18, 2018-07-01, 159668 则其在Tikv中排布情况如下所示：123456789101112131415161718192021t1_i1_intFlag&#123;10&#125;_1 --&gt; nullt1_i1_intFlag&#123;20&#125;_2 --&gt; nullt1_i1_intFlag&#123;30&#125;_3 --&gt; nullt1_r1 --&gt; [\"TiDB\", \"SQL Layer\", 10]t1_r2 --&gt; [\"TiKV\", \"KV Engine\", 20] t1_r3 --&gt; [\"PD\", \"Manager\", 30]t2_i1_bytesFlag&#123;A&#125;_1 --&gt; nullt2_i1_bytesFlag&#123;B&#125;_3 --&gt; nullt2_i1_bytesFlag&#123;C&#125;_2 --&gt; nullt2_i2_uintFlag&#123;18&#125;_3 --&gt; nullt2_i2_uintFlag&#123;19&#125;_1 --&gt; nullt2_i2_uintFlag&#123;19&#125;_2 --&gt; nullt2_i3_uintFlag&#123;2018-07-01&#125;_3 --&gt; nullt2_i3_uintFlag&#123;2019-03-20&#125;_2 --&gt; nullt2_i3_uintFlag&#123;2020-06-20&#125;_1 --&gt; nullt2_i4_uintFlag&#123;159668&#125; --&gt; 3t2_i4_uintFlag&#123;210283&#125; --&gt; 1t2_i4_uintFlag&#123;270447&#125; --&gt; 2t2_r1 --&gt; [\"XiaoMing\", \"A\", 19, 2020-06-20]t2_r2 --&gt; [\"XiaoHong\", \"B\", 19, 2019-03-20]t2_r3 --&gt; [\"XiaoWang\", \"C\", 18, 2018-07-01] tikv是一个全局有序的分布式Key-Value引擎，因此，通过以上的设计可以让同一个表下同一个indexID的索引按照ColumnsValue分布到一段连续的区间上.这个columnsValue的编码方式主要在codec模块中。 columnsValue在进行实际的编码时，会在编码开始前添加一个codeFlag，如下所示： 1234567891011121314const ( NilFlag byte = 0 bytesFlag byte = 1 compactBytesFlag byte = 2 intFlag byte = 3 uintFlag byte = 4 floatFlag byte = 5 decimalFlag byte = 6 durationFlag byte = 7 varintFlag byte = 8 uvarintFlag byte = 9 jsonFlag byte = 10 maxFlag byte = 250) 按照本人目前的理解，主要有两个作用： 一是用来识别不同数据类型的编码方案。比如int64 compareble就会用intFlag标记，string compareable就会用bytesFlag来标记。 二是方便统一不同类型对于边界值处理。在tidb中任何类型都有三个较为特殊的值，Null, MinNotNull, MaxValue.它主要用来表示一些筛选条件的range边界。这三个值的codeFlag是： 123Null --&gt; NilFlag byte = 0MinNotNull --&gt; bytesFlag byte = 1MaxValue --&gt; maxFlag byte = 250 比如 select * from table1 where value &lt; 15 这样一个查询， value的range就是[MinNotNull, 15). 对于这三个特殊值，并不依据具体的类型做编码，而是通过codeFlag这个字节来标识。结合key的编码比较方案，就可以实现对range边界的确定。 例如 1select from * from table2 where school &lt;= \"B\" AND school is Not Null 这样一个查询, 生成的range就是:[MaxNotNull, &quot;B&quot;]对应到tikv中的key编码就是:[t2_i1_bytesFlag, t2_i1_bytesFlag{B}]而包含Null的查询:1select from * from table2 where school &lt;= \"B\" 这样一个查询, 生成的range就是:[Null, &quot;B&quot;]对应到tikv中的key编码就是:[t2_i1_NilFlag, t2_i1_bytesFlag{B}]","path":"2020/11/26/TIDB源码学习笔记-Key编码后的比较/","date":"11-26","excerpt":"","tags":[{"name":"TIDB","slug":"TIDB","permalink":"https://haxisnake.github.io/tags/TIDB/"},{"name":"Golang","slug":"Golang","permalink":"https://haxisnake.github.io/tags/Golang/"}]},{"title":"TIDB源码学习笔记-range的生成","text":"point123456// Point is the end point of range interval.type point struct &#123; value types.Datum excl bool // exclude start bool&#125; ranger1234567891011121314151617181920212223242526272829// RangeType is alias for int.type RangeType int// RangeType constants.const ( IntRangeType RangeType = iota ColumnRangeType IndexRangeType)// Range represents a range generated in physical plan building phase.type Range struct &#123; LowVal []types.Datum HighVal []types.Datum LowExclude bool // Low value is exclusive. HighExclude bool // High value is exclusive.&#125;// fullRange is (-∞, +∞).var fullRange = []point&#123; &#123;start: true&#125;, &#123;value: types.MaxValueDatum()&#125;,&#125;FullIntRange unsigned [0, MaxUint64] signed [MinInt64, MaxInt64]FullRange [,MaxValueDatum) [null, +∞)FullNotNullRange (MinNotNullDatum, MaxValueDatum) (-∞, +∞)NullRange [,] [null, null] 单列range生成过程 通过builder将expression转化为[]point.主要的转化逻辑如下表所示： method return 备注 buildFromColumn [-inf, 0) (0, +inf] 列名表达式等价于列名为真。 buildFromConstant nil 或者 fullRange 当常量Eval转化出错，或者常量为Null或者常量为0时，返回nil，否则返回fullRange buildFromScalarFunc — buildFromBinOp a==NULL [,] a==1 [1, 1] a!=1 [-inf, 1) (1, +inf]) a&gt;1 (1, +inf] ast.LogicAnd 取交集 ast.LogicOr 取并集 取交集和取并集通过merge实现，通过flag区分。merge函数的假设： a, b 两个区间均已经做过去重 单个区间序列内部不会有重叠的部分 buildFromIsTrue [-inf, 0) (0, +inf] 还有包含is not和with null的处理 buildFromIsFalse [0, 0] 还有包含is not的处理 buildFromIn a in (1, 2, 3) {[1, 1], [2, 2], [3, 3]} 对每个点生成一个rangePoint，然后排序去重。 buildFromPatternLike a LIKE ‘abc%’ [abc, abd) a LIKE ‘abc_’ (abc, abd) 找前缀然后再计算起始点和终止点。 isNull [,] buildFromNot 对于Not前缀的处理 通过points2TableRanges和points2Ranges将point转化为range. 对于TableRange, 会将points中的null移除，同时将MinNotNull转化为MinInt64或者MinUint64, MaxValue转化为MaxInt64或者MaxUint64 再将point转化为range时，会将point转化为对应的FieldType，并将转化后的数据与原数据作比较，以此来修正point的excl属性，这部分逻辑在convertPoint中。举例 “a &gt; 1.9” 在1.9转化为整形时会变为“a&gt;=2”. 不同数据的比较逻辑放在datum.go中的CompareDatum中，比较特殊的几个类型的大小关系如下所示： MinNotNullDatum用来表示最小值即-inf MaxValueDatum用来表示最大值即+inf Null &lt; MinNotNull &lt; 其他类型的具体值 &lt; MaxValue 如果column无Null值，那么会移除[null, null]这样的range. 得到range之后，对于Column，会尝试进行range的裁剪和range的合并 range裁剪的应用场景猜测： 对于string列和bytes列，其有一定长度，比如col1 VarChar(6), 如果range中的端点长度超过这个值，即15，比如col1 &gt; “12345678”,那么这个端点就会被裁剪为 col1 &gt;= “123456” range 合并场景： [a, b] [c, d] 如果a &lt;= c 并且b &gt;= c，那么这两个区间就可以合并为[a, max(b, d)]","path":"2020/11/18/TIDB源码学习笔记-range的生成/","date":"11-18","excerpt":"","tags":[{"name":"TIDB","slug":"TIDB","permalink":"https://haxisnake.github.io/tags/TIDB/"},{"name":"Golang","slug":"Golang","permalink":"https://haxisnake.github.io/tags/Golang/"}]},{"title":"TIDB源码学习笔记-row的编码格式","text":"方案一 实现在util/rowcodec会记录当前行的空置和非空值数量 如果总列数大于255，会用uint32存储column id,否则使用byte存储column id. 会将同一行非空列排布在前面，空值列排布在后面，分别按照column id进行排序。 每一个非空列column id对应一个value.空值列的column id对应的value位置没有value重新赋值的操作。 会有一个notNullIdx来区分非空列和空列的界限。 最后转化为bytes的结构 CodecVer: 1 byte flag: 1 byte : large 1 small 0 numNotNullCols: 2 bytes numNullCols: 2 bytes colIDs32: uint32[] 转 byte[], 如果是small则为colIDs byte[] offsets32: uint32[] 转 byte[], 如果是small则为sffsets u16[] 转 byte[] data: byte[]方案二 这套方案比较简单，申请row长度2倍的datum数组，前面用来存储数值，后面用来存储column id 一一对应。","path":"2020/11/12/TIDB源码学习笔记-row的编码格式/","date":"11-12","excerpt":"","tags":[{"name":"TIDB","slug":"TIDB","permalink":"https://haxisnake.github.io/tags/TIDB/"},{"name":"Golang","slug":"Golang","permalink":"https://haxisnake.github.io/tags/Golang/"}]},{"title":"TIDB源码学习笔记-基本类型编解码方案","text":"TIDB基本类型的编码方案TIDB在编码不同的数据类型时会在编码前部添加一个字节的Flag用来区分不同的编码方案。同时，TIDB支持具有Memcomparable特性的编码，Memcomparable是指保证编码前和编码后的比较关系不变。在TIDB中，对于Key的编码都是要求Memcomparable的，而对于Value的编码则不要求Memcomparable，可以采用更节省空间的编码方案。 在进行编码前，会先依据数据类型预先申请一定尺寸的byte，然后再进行编码。 如下是目前的Flag，用于标识不同的编码方案1234567891011121314const ( NilFlag byte = 0 bytesFlag byte = 1 compactBytesFlag byte = 2 intFlag byte = 3 uintFlag byte = 4 floatFlag byte = 5 decimalFlag byte = 6 durationFlag byte = 7 varintFlag byte = 8 uvarintFlag byte = 9 jsonFlag byte = 10 maxFlag byte = 250) 下表是数据类型与Flag的对应关系以及相应的编码尺寸计算方法，具体的编码方案会在后续一一展开。 INT64comparable这种方式保证编码后的二进制排序结果与编码前的是完全相同的。 编码方法: uint64(num) ^ signMask const signMask uint64 = 0x8000000000000000 signed int binary after code 1 0000 0000 0000 0001 1000 0000 0000 0001 0 0000 0000 0000 0001 1000 0000 0000 0001 -1 1111 1111 1111 1111 0111 1111 1111 1111 -2 1111 1111 1111 1110 0111 1111 1111 1110 uncomparable:这种方法不能保证编码后是严格有序的。 编码方法: PutVarint函数 PutVarint: 步骤一：左移去掉符号位,如果是负数则对移位后的数取反 步骤二：将得到的数字从低到高每七位放入一个字节中，字节的第一位表示是否有后续字节。 举例： 原始数据 16进制表示 步骤一结果 步骤二结果 1 0x1 0x02 0x02 -1 0xffffffffffffffff 0x01 0x01 128 0x80 0x0100 0x8002 127 0x7f 0xfe 0xfe01 Uint64comparable直接写入二进制 uncomparable将二进制表示从低到高每七位放入一个字节中，字节的第一位表示是否有后续字节，其实就是去掉int64的uncomparable中符号处理那一步后剩下的步骤。 Float32 Float64Go的浮点数是按照IEEE 754浮点数标准存储的，TIDB直接对二进制表示进行操作 将正浮点数的符号位置1，将负浮点数的二进制表示按位取反 这样编码后的二进制是先比较符号位，再比较指数位，最后比较小数位，就可以保证编码值是升序的。对于负浮点数的比较因为是进行了取反，所以也能保证是升序的。如果要降序只要将编码值取反即可。123456789func encodeFloatToCmpUint64(f float64) uint64 &#123; u := math.Float64bits(f) if f &gt;= 0 &#123; u |= signMask &#125; else &#123; u = ^u &#125; return u&#125; Bytecomparable[group1][marker1]…[groupN][markerN] group 是补零之后的8字节切片 markder = 0xFF - 补零数量 举例: [] -&gt; [0, 0, 0, 0, 0, 0, 0, 0, 247] [1, 2, 3] -&gt; [1, 2, 3, 0, 0, 0, 0, 0, 250] [1, 2, 3, 0] -&gt; [1, 2, 3, 0, 0, 0, 0, 0, 251] [1, 2, 3, 4, 5, 6, 7, 8] -&gt; [1, 2, 3, 4, 5, 6, 7, 8, 255, 0, 0, 0, 0, 0, 0, 0, 0, 247] uncomparable数据长度 + 实际数据的二进制 String如果有排序规则，则使用排序规则得到的Bytes，否则直接用String本身的Bytes123456func encodeString(b []byte, val types.Datum, comparable bool) []byte&#123; if collate.NewCollationEnabled() &amp;&amp; comparable &#123; return encodeBytes(b, collate.GetCollator(val.Collation()).Key(val.GetString()), true) &#125; return encodeBytes(b, val.GetBytes(), comparable)&#125; MysqlTime先进行时区转化，全部转换为UTC时区后将Time转为uint64，再以uint64的形式进行编码。12345678910111213// ToPackedUint encodes Time to a packed uint64 value.//// 1 bit 0// 17 bits year*13+month (year 0-9999, month 0-12)// 5 bits day (0-31)// 5 bits hour (0-23)// 6 bits minute (0-59)// 6 bits second (0-59)// 24 bits microseconds (0-999999)//// Total: 64 bits = 8 bytes//// 0YYYYYYY.YYYYYYYY.YYdddddh.hhhhmmmm.mmssssss.ffffffff.ffffffff.ffffffff MysqlDurationduration可能有负值，所以无法直接用string来进行编码，采用的是同Int comparable相同的编码。 MysqlDecimal编码方式： precision + frac + WriteBin函数 WriteBin: 每 9 位十进制数字包装成 4 个字节. 其中整数和小数部分分别确定所需的存储空间. 如果数字位数为 9 的倍数, 则每 9 位十进制数字各采用 4 个字节进行存储, 对于剩余不足 9 位的数字, 所需的存储空间如下表所示： 剩余数字位数 存储所需字节数 0 0 1-2 1 3-4 2 5-6 3 7-9 4 举例： 1234567890.1234 以9位数字以及小数点为边界，可将decimal类型拆分为如下所示： 1 234567890 123400000 假设存储位数为有效位数为14，小数位为4，使用16进制表示为三部分： 00-00-00-01 0D-FB-38-D2 07-5A-EF-40 现在，中间部分已经是被填满，它存储了9位的十进制数字： ............ 0D-FB-38-D2 ............ 第一部分只有一个十进制数字，所以我们可以只用一个字节来存储，而不必浪费四个字节： 01 0D-FB-38-D2 ............ 现在，最后一部分，它是123400000，我们可以用两个字节来存储： 01 0D-FB-38-D2 04-D2 因此，我们将一个12个字节的数字使用7字节进行了表示，现在需要将最高位反转来得到最后的结果： 81 0D FB 38 D2 04 D2 如果要表示 -1234567890.1234，需要将各个位取反： 7E F2 04 C7 2D FB 2D 最高位反转，是为了保证有相同有效位数和有效小数位的DECIMAL类型编码后的二进制具有comparable特性。原因如下： 首先，最高位的置不影响原先数值的表示，因为不管第一部分剩多少位数字，它永远不会取到最高位，所以正数的DECIMAL类型的comparable可以得到保证。 其次，通过最高位置1再反转的形式，可以保证所有的负数的二进制编码都小于正数的二进制编码，即保证了正数和负数二进制编码之间的comparable。 最后，负数编码的comparable则是通过将正数编码所有位取反保证的。 MysqlEnum MysqlSet MysqlBit BinaryLiteral通过各自的ToNumber或者ToInt方法转化为uint64进行编码 MysqlJSONTypeCode + Value TypeCode:12345678910111213141516// TypeCodeObject indicates the JSON is an object.TypeCodeObject TypeCode = 0x01// TypeCodeArray indicates the JSON is an array.TypeCodeArray TypeCode = 0x03// TypeCodeLiteral indicates the JSON is a literal.TypeCodeLiteral TypeCode = 0x04// TypeCodeInt64 indicates the JSON is a signed integer.TypeCodeInt64 TypeCode = 0x09// TypeCodeUint64 indicates the JSON is a unsigned integer.TypeCodeUint64 TypeCode = 0x0a// TypeCodeFloat64 indicates the JSON is a double float number.TypeCodeFloat64 TypeCode = 0x0b// TypeCodeString indicates the JSON is a string.TypeCodeString TypeCode = 0x0cValue []byte NullNilFlag MinNotNullbytesFlag MaxValuemaxFlag 编码模块位置 util/codec tablecodec util/rowcodec","path":"2020/11/06/TIDB源码学习笔记-基本类型编解码方案/","date":"11-06","excerpt":"","tags":[{"name":"TIDB","slug":"TIDB","permalink":"https://haxisnake.github.io/tags/TIDB/"},{"name":"Golang","slug":"Golang","permalink":"https://haxisnake.github.io/tags/Golang/"}]},{"title":"二叉树的遍历方法总结","text":"二叉树的遍历方法总结二叉树的遍历有前序遍历，中序遍历，后续遍历和层序遍历，这几种方法都可以通过递归和循环来实现。 二叉树数据结构定义123456789/*** Definition for a binary tree node.* struct TreeNode &#123;* int val;* TreeNode *left;* TreeNode *right;* TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125;* &#125;;*/ 二叉树的前序遍历 递归实现 1234567891011121314151617181920class Solution &#123;public: vector&lt;int&gt; preorderTraversal(TreeNode* root) &#123; if(!root)&#123; return &#123;&#125;; &#125; vector&lt;int&gt; res; preorderTraversal(root,res); return res; &#125; void preorderTraversal(TreeNode* root, vector&lt;int&gt;&amp; res)&#123; if(!root)&#123; return; &#125; res.push_back(root-&gt;val); preorderTraversal(root-&gt;left,res); preorderTraversal(root-&gt;right,res); return; &#125;&#125;; 循环实现 1234567891011121314151617181920212223class Solution &#123;public: vector&lt;int&gt; preorderTraversal(TreeNode* root) &#123; if(!root)&#123; return &#123;&#125;; &#125; vector&lt;int&gt; res; stack&lt;TreeNode*&gt; nodes; nodes.push(root); while(!nodes.empty())&#123; TreeNode* node = nodes.top(); nodes.pop(); res.push_back(node-&gt;val); if(node-&gt;right)&#123; nodes.push(node-&gt;right); &#125; if(node-&gt;left)&#123; nodes.push(node-&gt;left); &#125; &#125; return res; &#125;&#125;; 二叉树的中序遍历 递归实现 1234567891011121314151617class Solution &#123;public: vector&lt;int&gt; inorderTraversal(TreeNode* root) &#123; if(!root) return&#123;&#125;; vector&lt;int&gt; res; inorderTraversal(root,res); return res; &#125; void inorderTraversal(TreeNode* root, vector&lt;int&gt;&amp; res)&#123; if(!root)&#123; return; &#125; inorderTraversal(root-&gt;left, res); res.push_back(root-&gt;val); inorderTraversal(root-&gt;right,res); &#125;&#125;; 循环实现 12345678910111213141516171819class Solution &#123;public: vector&lt;int&gt; inorderTraversal(TreeNode* root) &#123; stack&lt;TreeNode*&gt; s; vector&lt;int&gt; res; TreeNode* r = root; while(!s.empty() || r!=NULL)&#123; while(r!=NULL)&#123; s.push(r); r = r-&gt;left; &#125; r = s.top(); s.pop(); res.push_back(r-&gt;val); r=r-&gt;right; &#125; return res; &#125;&#125;; 二叉树的后序遍历 递归实现 1234567891011121314151617class Solution &#123;public: vector&lt;int&gt; postorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; res; if(!root) return &#123;&#125;; postorderTraversal(root,res); return res; &#125; void postorderTraversal(TreeNode* root, vector&lt;int&gt;&amp; res)&#123; if(!root)&#123; return; &#125; postorderTraversal(root-&gt;left,res); postorderTraversal(root-&gt;right,res); res.push_back(root-&gt;val); &#125;&#125;; 循环实现 12345678910111213141516171819202122232425262728class Solution &#123;public: vector&lt;int&gt; postorderTraversal(TreeNode* root) &#123; if(!root) return &#123;&#125;; stack&lt;TreeNode*&gt; nodes; vector&lt;int&gt; res; TreeNode* pre = NULL; nodes.push(root); while(!nodes.empty())&#123; TreeNode* node = nodes.top(); if( (node-&gt;left==NULL &amp;&amp; node-&gt;right==NULL) || (pre!=NULL &amp;&amp; (node-&gt;left==pre || node-&gt;right==pre)))&#123; pre = node; res.push_back(node-&gt;val); nodes.pop(); &#125;else&#123; if(node-&gt;right)&#123; nodes.push(node-&gt;right); &#125; if(node-&gt;left)&#123; nodes.push(node-&gt;left); &#125; &#125; &#125; return res; &#125; &#125;; 二叉树的层序遍历 递归实现 1234567891011121314151617181920class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; levelOrder(TreeNode* root) &#123; vector&lt;vector&lt;int&gt; &gt; res; if(root==NULL) return res; levelOrder(root,res,0); return res; &#125; void levelOrder(TreeNode* root, vector&lt;vector&lt;int&gt; &gt;&amp;res, int level)&#123; if(root==NULL) return; if(res.size()==level)&#123; res.push_back(vector&lt;int&gt;(1,root-&gt;val)); &#125;else&#123; res[level].push_back(root-&gt;val); &#125; levelOrder(root-&gt;left,res,level+1); levelOrder(root-&gt;right,res,level+1); return; &#125;&#125;; 循环实现 1234567891011121314151617181920212223242526272829class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; levelOrder(TreeNode* root) &#123; vector&lt;vector&lt;int&gt; &gt; res; if(!root) return res; queue&lt;TreeNode*&gt; nodes; nodes.push(root); int level=0; while(!nodes.empty())&#123; int level_size = nodes.size(); int count = 0; res.push_back(vector&lt;int&gt;(0)); while(count&lt;level_size)&#123; TreeNode* node = nodes.front(); nodes.pop(); res[level].push_back(node-&gt;val); count++; if(node-&gt;left)&#123; nodes.push(node-&gt;left); &#125; if(node-&gt;right)&#123; nodes.push(node-&gt;right); &#125; &#125; level++; &#125; return res; &#125;&#125;;","path":"2019/10/25/二叉树的遍历方法总结/","date":"10-25","excerpt":"","tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://haxisnake.github.io/tags/数据结构/"}]},{"title":"设置linux开机启动脚本自动联网认证","text":"由于学校的网络需要认证上网,每次服务器上网都用个人账号认证，因此需要配置下开机启动脚本使其自动上网。(其实就是没钱惹的祸) 一、上网认证的脚本先安装依赖:123sudo apt-get install python-pipsudo pip3 install schedule sudo pip3 install argparse task.py1234567891011121314151617181920212223242526272829303132333435363738394041424344import scheduleimport timefrom urllib.parse import quote, unquoteimport requestsimport argparsedef job(User,Pass): base_url = 'http://auth.dlut.edu.cn' try: resp = requests.get(base_url) print(\"conneting...\") except Exception: #print(\"Already connected...\") return query = resp.text[resp.text.find('wlanuserip'):resp.text.find('&lt;/script&gt;')] query_str = quote(quote(query)) url = base_url + '/eportal/InterFace.do?method=login' data = &#123; 'userId': User, # username 1 'password': Pass, # password 'service': '', # empty 'queryString': query_str, 'operatorPwd': '', # empty 'operatorUserId': '', # empty 'validcode': '', # empty &#125; headers = &#123;'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8'&#125; resp = requests.post(url, data, headers=headers) print(resp.status_code) print(resp.text)parser = argparse.ArgumentParser(description='connect to dlut')parser.add_argument('-u',type=str, help='user name')parser.add_argument('-p',type=str, help='user name')args = parser.parse_args()User = args.uPass = args.pjob(User, Pass)schedule.every(300).minutes.do(job,User,Pass)while True: schedule.run_pending() time.sleep(300) 其主要作用是进行认证链接,命令行调用格式为:1python3 task.py -u username -p passwd username是认证用户名，passwd是对应密码 二、编写bash脚本调用登陆脚本connect.sh123456#!/bin/bashpython3 /home/sie/netset/task.py -u username -p passwd &amp;``` 添加可执行权限:``` bashchmod +x connect.sh 将connect.sh和task.py都放到同一目录下 设为path_to_sp 三、在/etc/rc.local里添加开机启动脚本命令 配置rc-local.service服务使其能够执行开机启动脚本 参考教程 root权限创建/etc/rc.local文件并写入开机启动的脚本 1234567891011121314#!/bin/sh -e# # rc.local## This script is executed at the end of each multiuser runlevel.# Make sure that the script will \"exit 0\" on success or any other# value on error.## In order to enable or disable this script just change the execution# bits.## By default this script does nothing.su -s /bin/sh sie -c\"path_to_sp/connect.sh\"exit 0 其中path_to_sp为connect.sh和task.py的目录 至此开机启动配置结束。 以前一直想搞定开机启动脚本的事情，但是总不得其要点，特此记录，以后还要多多了解原理才是。","path":"2019/05/29/设置linux开机启动脚本自动联网认证/","date":"05-29","excerpt":"","tags":[{"name":"服务器维护","slug":"服务器维护","permalink":"https://haxisnake.github.io/tags/服务器维护/"}]},{"title":"服务器环境搭建","text":"ubuntu18.04-servercuda10.1cudann7.5.0 安装显卡驱动 linux查看显卡型号 lshw -numeric -C display 下载nvidia官方驱动 官网链接 bios禁用禁用secure boot 禁用nouveau 打开文件 sudo vim /etc/modprobe.d/blacklist.conf 在最后一行添加: blacklist nouveau 执行如下命令生效 sudo update-initramfs -u 重启 使用命令查看nouveau有没有运行 lsmod | grep nouveau # 没输出代表禁用生效 停止可视化界面 sudo telinit 3 安装驱动 先添加可执行权限 sudo chmod a+x filename.run 执行安装： sudo ./filename.run -no-opengl-files -noopengl-files这个参数一定要加，否则会循环登录 安装CUDA10.1 下载cuda10.1安装文件 官网链接 运行安装 执行安装文件进行安装，同nvidia驱动的执行方式。 注意此时不需要选择安装驱动。驱动版本要注意跟cuda版本相对应。 安装cudann请见官网安装教程","path":"2019/05/07/服务器环境搭建ubuntu18-04-server-cuda10-1-cudann/","date":"05-07","excerpt":"","tags":[]},{"title":"OpenPose环境搭建笔记","text":"OpenPose环境搭建笔记编译caffe recipe for target ‘.build_release/src/caffe/proto/caffe.pb.o’ failed 参考教程：https://blog.csdn.net/w5688414/article/details/79478695 ./include/caffe/util/hdf5.hpp:6:18: fatal error: hdf5.h: No such file or directory 解决办法：在Makefile.config找到以下行并添加蓝色部分 INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-Linux-gnu/hdf5/serial 3.1 如果仍然提示找不到lhdf5和lhdf5_hl(这是因为ubuntu16.04的文件包含位置发生了变化，尤其是需要用到的hdf5的位置，所以需要更改这一路径)选自caffe —找不到lhdf5_hl和lhdf5的错误 解决办法：然后根据情况执行下面两句： cd /usr/lib/x86_64-linux-gnu sudo ln -s libhdf5_serial.so.10.1.0 libhdf5.so sudo ln -s libhdf5_serial_hl.so.10.0.2 libhdf5_hl.so https://github.com/BVLC/caffe/issues/6359 /usr/include/c++/5/typeinfo:39:37: error: expected ‘}’ before end of line/usr/include/c++/5/typeinfo:39:37: error: expected unqualified-id before end of line/usr/include/c++/5/typeinfo:39:37: error: expected ‘}’ before end of line/usr/include/c++/5/typeinfo:39:37: error: expected ‘}’ before end of line/usr/include/c++/5/typeinfo:39:37: error: expected ‘}’ before end of line/usr/include/c++/5/typeinfo:39:37: error: expected declaration before end of lineMakefile:588: recipe for target ‘.build_release/src/caffe/proto/caffe.pb.o’ failedmake: *** [.build_release/src/caffe/proto/caffe.pb.o] Error 1 CXXFLAGS += -pthread -fPIC $(COMMON_FLAGS) $(WARNINGS) -std=c++11NVCCFLAGS += -D_FORCE_INLINES -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS) -std=c++11LINKFLAGS += -pthread -fPIC $(COMMON_FLAGS) $(WARNINGS) -std=c++11 Unsupported gpu architecture ‘compute_20’ 注释Makefile.config 中 : # CUDA architecture setting: going with all of them. # For CUDA &lt; 6.0, comment the *_50 through *_61 lines for compatibility. # For CUDA &lt; 8.0, comment the *_60 and *_61 lines for compatibility. # For CUDA &gt;= 9.0, comment the *_20 and *_21 lines for compatibility. CUDA_ARCH := -gencode arch=compute_30,code=sm_30 \\ -gencode arch=compute_35,code=sm_35 \\ -gencode arch=compute_50,code=sm_50 \\ -gencode arch=compute_52,code=sm_52 \\ -gencode arch=compute_60,code=sm_60 \\ -gencode arch=compute_61,code=sm_61 \\ -gencode arch=compute_61,code=compute_61 leveldbhttps://blog.csdn.net/oeljeklaus/article/details/78802922 https://blog.csdn.net/fogxcg/article/details/75332146 build opencv3.4 cmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local -D PYTHON3_EXECUTABLE=/usr/bin/python3 -D PYTHON_INCLUDE_DIR=/usr/include/python3 -D PYTHON_INCLUDE_DIR2=/usr/include/x86_64-linux-gnu/python3.5m -D PYTHON_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.5m.so -D PYTHON3_NUMPY_INCLUDE_DIRS=/usr/lib/python3/dist-packages/numpy/core/include/ levelDB出错 https://blog.csdn.net/jyl1999xxxx/article/details/80583465 glog 和 gflags 的安装https://www.cnblogs.com/burningTheStar/p/6986048.html-fPIChttps://github.com/BVLC/caffe/issues/2171 make runtest .build_release/tools/caffe: error while loading shared libraries: libopencv_imgcodecs.so.3.4: cannot open shared object file: No such file or directoryMakefile:542: recipe for target ‘runtest’ failed make runtest https://blog.csdn.net/wonengguwozai/article/details/52724409 编译openpose cuda结构不共存 Unsupported gpu architecture ‘compute_xx’ 在cmake-gui 中选择 CUDA_ARCH 为mannul 然后再删掉其中不符合的结构 g++: error trying to exec ‘cc1plus’: execvp: 没有那个文件或目录 gcc g++ 版本不兼容 https://blog.csdn.net/yile0000/article/details/80105625 nvidia驱动 https://blog.csdn.net/wf19930209/article/details/81877822 sudo service lightdm stop gflags.cc is being linked both statically and dynamically https://github.com/google/glog/issues/53 修改CmakeCache.txt中的GFLAGS_LIBRARY:FILEPATH=/usr/local/lib/libgflags.a改为：GFLAGS_LIBRARY:FILEPATH=/usr/local/lib/libgflags.so然后重新编译 [libprotobuf ERROR google/protobuf/message_lite.cc:123] Can’t parse message of type “caffe.NetParameter” because it is missing required fields: layer[0].clip_param.min, layer[0].clip_param.max 要用openpose自带的caffe库 选择openpose编译caffe时选项可以在3rdparty/caffe中设置编译参数","path":"2019/04/09/OpenPose环境搭建笔记/","date":"04-09","excerpt":"","tags":[]},{"title":"使用python搭建小型搜索引擎","text":"项目代码链接 一、目标为准备信息检索课程的期末大作业，因此我使用python搭建了一个小型的搜索引擎，其功能是检索大工新闻网的新闻。 二、原理和工具简介2.1 原理该搜索引擎的原理是采用scrapy对大工新闻网进行爬虫，提取出文字新闻，并将新闻内容存入数据库A，再利用Django框架搭建一个搜索服务器，在服务器上部署Haystack+Whoosh搜索引擎，使用jieba分词工具来进行中文分词和停用词过滤。通过搜索引擎工具建立索引文件后，在前端完成用户交互界面，实现一个完整的小型搜索引擎。 2.2 工具简介 Scrapy Python开发的一个快速、高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据。Scrapy用途广泛，可以用于数据挖掘、监测和自动化测试。 在本项目中用来爬取网站数据。 Django Django是一个开放源代码的Web应用框架，由Python写成。采用了MVC的框架模式，即模型M，视图V和控制器C。 在本项目用来做搜索服务器的框架。 Haystack+Whoosh Haystack是一个Django上的应用，可以用于整合搜索引擎，它只依赖于它自身的代码，利用它可以切换不同的搜索引擎工具。Whoosh是一个索引文本和搜索文本的类库，它可以提供搜索文本的服务。 在本项目中使用Haystack将Whoosh部署到Django服务器作为搜索引擎后端。 Jieba Jieba是一个python实现的分词库，对中文有着很强大的分词能力。 在本项目用于对新闻进行中文分词和停用词过滤。 三、开发环境和运行环境3.1 开发环境 win 10 python 3.6.5 scrapy 1.5.1 安装教程 Django 2.1.3 安装教程 Haystack+Whoosh 配置教程 Jieba 0.39 配置教程 3.2 运行环境同开发环境 四、系统模块4.1 网络爬虫模块定义用于Scrapy爬虫的数据类型，包括链接、标题和文章内容:1234class NewsItem(scrapy.Item): url = scrapy.Field() title = scrapy.Field() content = scrapy.Field() 编写爬虫策略:爬虫策略的制定依据于网页源代码的链接形式，由于要爬取的是文字类新闻，所以要跟进与文字类新闻的链接。对于具体的新闻页利用回调函数爬取其链接、标题和内容。而对于新闻列表页，需要跟进下一页的链接。具体规则代码如下: 12345678910111213141516171819202122class NewsSpider(CrawlSpider): print(\"news spider starting\") name = 'news' allowed_domains = ['news.dlut.edu.cn'] start_urls = ['http://news.dlut.edu.cn/'] rules = ( # 对于新闻页链接进行跟进 Rule(LinkExtractor(allow=(\"xw/[a-z]+.htm\"))), # 对于详细新闻页利用parse_item回调函数进行内容爬取 Rule(LinkExtractor(allow=(\"info/\\d&#123;4,&#125;/\\d&#123;3,&#125;\\.htm\")),callback=\"parse_item\"), # 对于新闻列表中的下一页链接进行跟进 Rule(LinkExtractor(allow=(\"\\d&#123;1,&#125;.htm\"),restrict_xpaths=\"//a[@class='Next']\")), ) def parse_item(self, response): self.log(\"Hi, this is a new page! %s\"% response.url) item = NewsItem() item['title'] = response.xpath('/html/head/title/text()').extract()[0] item['url'] = response.url item['content']=response.xpath(\"//div[@class='cont-detail fs-small']/p/text()\").extract() yield item 使用pipline机制将数据保存至数据库当中1234567891011121314151617181920212223242526272829class SpiderprojectPipeline(object): def process_item(self, item, spider): if spider.name == 'news': conn = sqlite3.connect('db.sqlite3') cursor = conn.cursor() title = item['title'] url = item['url'] content_tmp = item['content'] content=\"\" for p in content_tmp: content+=p.strip() sql_search = 'select arturl from search_article where arturl==\"%s\"' % (url) sql = 'insert into articles_article(title, content, arturl) values(\"%s\", \"%s\", \"%s\")'%(title, content, url) try: #如果当前数据库中不存在该条新闻，则将新闻保存至数据库当中 cursor.execute(sql_search) result_search = cursor.fetchone() if result_search is None or result_search[0].strip()=='': cursor.execute(sql) result=cursor.fetchone() conn.commit() cursor.execute(sql) result=cursor.fetchone() conn.commit() except Exception as e: print(\"&gt;&gt;&gt; catch exception !\") print(e) conn.rollback() return item 4.2 搜索模块在要进行搜索的应用的models.py文件中建立model类用来表示要进行搜索的新闻文章 1234class Article(models.Model): title = models.CharField(max_length=50) arturl = models.CharField(max_length=200) content = models.CharField(max_length=1000) 同时使用django命令python manage.py makemigrations和python manage.py migrate生成数据库文件，并用爬虫得到的数据库替换生成的数据库。 在django框架中配置Haystack+Whoosh来引入搜索模块 123456789101112# 配置搜索引擎后端HAYSTACK_CONNECTIONS=&#123; 'default':&#123; 'ENGINE': 'articles.whoosh_cn_backend.WhooshEngine', # 索引文件路径 'PATH': os.path.join(BASE_DIR, 'whoosh_index'), # 在项目目录下创建文件夹 whoosh_index &#125;&#125;# 当添加、修改、删除数据时，自动生成索引HAYSTACK_SIGNAL_PROCESSOR = 'haystack.signals.RealtimeSignalProcessor'# 每页显示十条搜索结果HAYSTACK_SEARCH_RESULTS_PER_PAGE = 10 在要进行搜索的应用的目录下建立search_indexes.py文件 123456789101112from haystack import indexesfrom articles.models import Articleclass ArticleIndex(indexes.SearchIndex, indexes.Indexable): #类名必须为需要检索的Model_name+Index，这里需要检索Article，所以创建ArticleIndex text = indexes.CharField(document=True, use_template=True) #创建一个text字段 def get_model(self): #重载get_model方法，必须要有！ return Article def index_queryset(self, using=None): #重载index_..函数 \"\"\"Used when the entire index for model is updated.\"\"\" return self.get_model().objects.all() 在articles\\templates\\search\\indexes\\articles\\下建立article_text.txt文件确定搜索内容 123&#123;&#123; object.title &#125;&#125;&#123;&#123; object.content &#125;&#125;&#123;&#123; object.url &#125;&#125; 4.2 预处理模块使用jieba来进行中文分词，需要在whoosh_cn_backend文件中替换StemmingAnalyzer为ChineseAnalyzer 同时引入停用词表，配置ChineseAnalyzer使其支持停用词过滤 1234567891011121314151617181920212223242526import jiebaimport reimport os# 导入停用词过滤表stop_file_dir=os.path.dirname(os.path.dirname(os.path.abspath(__file__)))STOP_WORDS = frozenset([line.strip() for line in open(os.path.join(stop_file_dir, 'stop.txt'),'r',encoding='gbk').readlines()])accepted_chars = re.compile(r\"[\\u4E00-\\u9FD5]+\")class ChineseTokenizer(Tokenizer): def __call__(self, text, **kargs): words = jieba.tokenize(text, mode=\"search\") token = Token() for (w, start_pos, stop_pos) in words: if not accepted_chars.match(w) and len(w) &lt;= 1: continue token.original = token.text = w token.pos = start_pos token.startchar = start_pos token.endchar = stop_pos yield token def ChineseAnalyzer(stoplist=STOP_WORDS, minsize=1, stemfn=stem, cachesize=50000): return (ChineseTokenizer() | LowercaseFilter() | StopFilter(stoplist=stoplist, minsize=minsize) | StemFilter(stemfn=stemfn, ignore=None, cachesize=cachesize)) 配置完成后使用python manage.py rebuild_index建立搜索索引 4.4 交互模块搜索首页html关键代码： 12345&lt;form method='get' action=\"/search/\" target=\"_blank\"&gt; &lt;input type=\"text\" name=\"q\"&gt; &lt;br&gt; &lt;input type=\"submit\" value=\"查询\"&gt;&lt;/form&gt; 首页如下图所示： 查询结果页html关键代码： 12345678910111213141516171819&#123;% load highlight %&#125;&lt;h3&gt;搜索&amp;nbsp;&lt;b&gt;&#123;&#123;query&#125;&#125;&lt;/b&gt;&amp;nbsp;结果如下：&lt;/h3&gt;&lt;ul&gt;&#123;%for item in page%&#125; &lt;li&gt;&#123;&#123;item.object.title|safe&#125;&#125;&lt;/li&gt; &lt;p&gt;&#123;% highlight item.object.content with query %&#125;&lt;/p&gt; &lt;a href=\"&#123;&#123;item.object.arturl&#125;&#125;\"&gt;&#123;&#123;item.object.arturl&#125;&#125;&lt;/a&gt;&#123;%empty%&#125; &lt;li&gt;啥也没找到&lt;/li&gt;&#123;%endfor%&#125;&lt;/ul&gt;&lt;hr&gt;&#123;%for pindex in page.paginator.page_range%&#125; &#123;%if pindex == page.number%&#125; &#123;&#123;pindex&#125;&#125;&amp;nbsp;&amp;nbsp; &#123;%else%&#125; &lt;a href=\"?q=&#123;&#123;query&#125;&#125;&amp;amp;page=&#123;&#123;pindex&#125;&#125;\"&gt;&#123;&#123;pindex&#125;&#125;&lt;/a&gt;&amp;nbsp;&amp;nbsp; &#123;%endif%&#125;&#123;%endfor%&#125; 其中使用 12&#123;% load highlight %&#125;&lt;p&gt;&#123;% highlight item.object.content with query %&#125;&lt;/p&gt; 进行搜索结果的高亮显示 最终搜索页面如下图所示： 五、项目代码代码链接","path":"2018/12/31/使用python搭建小型搜索引擎/","date":"12-31","excerpt":"","tags":[{"name":"Django","slug":"Django","permalink":"https://haxisnake.github.io/tags/Django/"},{"name":"Python","slug":"Python","permalink":"https://haxisnake.github.io/tags/Python/"},{"name":"Scrapy","slug":"Scrapy","permalink":"https://haxisnake.github.io/tags/Scrapy/"},{"name":"Haystack","slug":"Haystack","permalink":"https://haxisnake.github.io/tags/Haystack/"},{"name":"Whoosh","slug":"Whoosh","permalink":"https://haxisnake.github.io/tags/Whoosh/"},{"name":"Jieba","slug":"Jieba","permalink":"https://haxisnake.github.io/tags/Jieba/"}]},{"title":"树莓派3B——turtlebot3——ROS开发环境搭建问题记录","text":"由于一个比赛项目需要在ROS上做开发，但是按照网上教程搭建开发环境出现了一些问题，因此在此做简单整理，本笔记的开发环境如下： 硬件环境：turtlebot3 burger(用的其自带的树莓派为raspberry3B) 树莓派系统版本：ubuntu-mate-16.04.2-desktop-armhf PC系统版本： ubuntu-16.04.3-desktop-amd64 教程参考： https://www.ncnynl.com/archives/201702/1392.html 问题记录问题一问题描述：wget 安装脚本时验证出错导致脚本无法下载 解决方法：在wget命令后加上–no-check-certificate选项即可 问题二问题描述：git clone 出现CAfile: /etc/ssl/certs/ca-certificates.crt CRLfile: none错误 解决方式：运行 export GIT_SSL_NO_VERIFY=1 问题三问题描述：安装turtlebot依赖包之后找不到catkin_make命令 解决方式：重新执行 source /opt/ros/kinetic/setup.sh 问题四问题描述：cakin_make时找不到interactive_maker模块 解决方式：修改安装脚本，使其安装desktop_full版本 问题五问题描述：checksum error when launching turtlebot3_bringup 解决方式：更新OpenCR固件至最新版与ROS版本相匹配","path":"2018/07/18/树莓派3B-turtlebot3ros开发环境搭建问题记录/","date":"07-18","excerpt":"","tags":[{"name":"环境搭建","slug":"环境搭建","permalink":"https://haxisnake.github.io/tags/环境搭建/"},{"name":"raspberry3B","slug":"raspberry3B","permalink":"https://haxisnake.github.io/tags/raspberry3B/"},{"name":"ROS","slug":"ROS","permalink":"https://haxisnake.github.io/tags/ROS/"},{"name":"turtlebot3","slug":"turtlebot3","permalink":"https://haxisnake.github.io/tags/turtlebot3/"}]},{"title":"opencv3-ubuntu16.04-install","text":"123456789101112131415161718sudo apt-get install cmakesudo apt-get install python3-dev python3-numpysudo apt-get install gcc g++sudo apt-get install libgtk2.0-devsudo apt-get install libv4l-devsudo apt-get install libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-devsudo apt-get install sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev liblapacke-devsudo apt-get install libxvidcore-dev libx264-dev sudo apt-get install libatlas-base-dev gfortransudo apt-get install ffmpeg sudo apt-get install gitgit clone https://github.com/opencv/opencv.gitcmake dir/of/opencv/sourcesudo make -j4 sudo make install","path":"2018/07/17/opencv3-ubuntu16-04-install/","date":"07-17","excerpt":"","tags":[{"name":"环境搭建","slug":"环境搭建","permalink":"https://haxisnake.github.io/tags/环境搭建/"},{"name":"opencv3","slug":"opencv3","permalink":"https://haxisnake.github.io/tags/opencv3/"}]},{"title":"树莓派3B+编译安装opencv3","text":"一、更新源12mv sources.list /etc/apt/sources.list mv raspi.list /etc/apt/sources.list.d/raspi.list 更新源的配置，注意文件存放的位置文件sources.list和raspi.list具体内容如下 sources.list文件: deb http://mirrors.ustc.edu.cn/raspbian/raspbian/ stretch main contrib non-free rpi deb http://mirrors.aliyun.com/raspbian/raspbian/ stretch main contrib non-free rpi deb http://mirrors.tuna.tsinghua.edu.cn/raspbian/raspbian/ stretch main contrib non-free rpi deb http://mirrors.neusoft.edu.cn/raspbian/raspbian/ stretch main contrib non-free rpi raspi.list文件:1234deb http://mirrors.ustc.edu.cn/raspbian/raspbian/ stretch main uideb http://mirrors.aliyun.com/raspbian/raspbian/ stretch main uideb http://mirrors.tuna.tsinghua.edu.cn/raspbian/raspbian/ stretch main uideb http://mirrors.neusoft.edu.cn/raspbian/raspbian/ stretch main ui 在终端执行更新命令:12sudo apt-get updatesudo apt-get upgrade 二、安装依赖包123456789sudo apt-get install build-essential cmake git pkg-config sudo apt-get install libjpeg8-dev sudo apt-get install libtiff5-dev sudo apt-get install libjasper-dev sudo apt-get install libpng12-devsudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libv4l-devsudo apt-get install libgtk2.0-devsudo apt-get install libatlas-base-dev gfortran 注意：降级安装有些安装包依赖的版本低需要降级安装，如下，对depends后面的进行降级安装1sudo aptitude install xxxx 三、下载源码1git clone https://github.com/opencv/opencv.git 四、编译1234cmake dir/of/opencv/sourcesudo make -j4 sudo make installsudo ldconfig","path":"2018/07/17/树莓派3B-编译安装opencv3/","date":"07-17","excerpt":"","tags":[{"name":"环境搭建","slug":"环境搭建","permalink":"https://haxisnake.github.io/tags/环境搭建/"},{"name":"opencv3","slug":"opencv3","permalink":"https://haxisnake.github.io/tags/opencv3/"},{"name":"raspberry3B+","slug":"raspberry3B","permalink":"https://haxisnake.github.io/tags/raspberry3B/"}]}]}