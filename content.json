{"pages":[{"title":"404","text":"","path":"404/index.html","date":"05-07","excerpt":""},{"title":"about","text":"关于我研一在读，转专业至计算机，菜鸟一只","path":"about/index.html","date":"07-17","excerpt":""},{"title":"categories","text":"","path":"categories/index.html","date":"07-17","excerpt":""},{"title":"tags","text":"","path":"tags/index.html","date":"07-17","excerpt":""},{"title":"search","text":"","path":"search/index.html","date":"05-07","excerpt":""}],"posts":[{"title":"二叉树的遍历方法总结.md","text":"二叉树的遍历方法总结二叉树的遍历有前序遍历，中序遍历，后续遍历和层序遍历，这几种方法都可以通过递归和循环来实现。 二叉树数据结构定义/** * Definition for a binary tree node. * struct TreeNode { * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) {} * }; */ 二叉树的前序遍历 递归实现 class Solution { public: vector&lt;int&gt; preorderTraversal(TreeNode* root) { if(!root){ return {}; } vector&lt;int&gt; res; preorderTraversal(root,res); return res; } void preorderTraversal(TreeNode* root, vector&lt;int&gt;&amp; res){ if(!root){ return; } res.push_back(root-&gt;val); preorderTraversal(root-&gt;left,res); preorderTraversal(root-&gt;right,res); return; } }; 循环实现 class Solution { public: vector&lt;int&gt; preorderTraversal(TreeNode* root) { if(!root){ return {}; } vector&lt;int&gt; res; stack&lt;TreeNode*&gt; nodes; nodes.push(root); while(!nodes.empty()){ TreeNode* node = nodes.top(); nodes.pop(); res.push_back(node-&gt;val); if(node-&gt;right){ nodes.push(node-&gt;right); } if(node-&gt;left){ nodes.push(node-&gt;left); } } return res; } }; 二叉树的中序遍历 递归实现 class Solution { public: vector&lt;int&gt; inorderTraversal(TreeNode* root) { if(!root) return{}; vector&lt;int&gt; res; inorderTraversal(root,res); return res; } void inorderTraversal(TreeNode* root, vector&lt;int&gt;&amp; res){ if(!root){ return; } inorderTraversal(root-&gt;left, res); res.push_back(root-&gt;val); inorderTraversal(root-&gt;right,res); } }; 循环实现 class Solution { public: vector&lt;int&gt; inorderTraversal(TreeNode* root) { if(!root) return {}; vector&lt;int&gt; res; stack&lt;TreeNode*&gt; nodes; nodes.push(root); TreeNode* p = root; while(p-&gt;left!=NULL){ nodes.push(p-&gt;left); p=p-&gt;left; } while(!nodes.empty()){ TreeNode * node = nodes.top(); nodes.pop(); res.push_back(node-&gt;val); if(node-&gt;right){ nodes.push(node-&gt;right); TreeNode* p = node-&gt;right; while(p-&gt;left!=NULL){ nodes.push(p-&gt;left); p=p-&gt;left; } } } return res; } }; 二叉树的后序遍历 递归实现 class Solution { public: vector&lt;int&gt; postorderTraversal(TreeNode* root) { vector&lt;int&gt; res; if(!root) return {}; postorderTraversal(root,res); return res; } void postorderTraversal(TreeNode* root, vector&lt;int&gt;&amp; res){ if(!root){ return; } postorderTraversal(root-&gt;left,res); postorderTraversal(root-&gt;right,res); res.push_back(root-&gt;val); } }; 循环实现 class Solution { public: vector&lt;int&gt; postorderTraversal(TreeNode* root) { if(!root) return {}; stack&lt;TreeNode*&gt; nodes; vector&lt;int&gt; res; TreeNode* pre = NULL; nodes.push(root); while(!nodes.empty()){ TreeNode* node = nodes.top(); if( (node-&gt;left==NULL &amp;&amp; node-&gt;right==NULL) || (pre!=NULL &amp;&amp; (node-&gt;left==pre || node-&gt;right==pre))){ pre = node; res.push_back(node-&gt;val); nodes.pop(); }else{ if(node-&gt;right){ nodes.push(node-&gt;right); } if(node-&gt;left){ nodes.push(node-&gt;left); } } } return res; } }; 二叉树的层序遍历 递归实现 class Solution { public: vector&lt;vector&lt;int&gt;&gt; levelOrder(TreeNode* root) { vector&lt;vector&lt;int&gt; &gt; res; if(root==NULL) return res; levelOrder(root,res,0); return res; } void levelOrder(TreeNode* root, vector&lt;vector&lt;int&gt; &gt;&amp;res, int level){ if(root==NULL) return; if(res.size()==level){ res.push_back(vector&lt;int&gt;(1,root-&gt;val)); }else{ res[level].push_back(root-&gt;val); } levelOrder(root-&gt;left,res,level+1); levelOrder(root-&gt;right,res,level+1); return; } }; 循环实现 class Solution { public: vector&lt;vector&lt;int&gt;&gt; levelOrder(TreeNode* root) { vector&lt;vector&lt;int&gt; &gt; res; if(!root) return res; queue&lt;TreeNode*&gt; nodes; nodes.push(root); int level=0; while(!nodes.empty()){ int level_size = nodes.size(); int count = 0; res.push_back(vector&lt;int&gt;(0)); while(count&lt;level_size){ TreeNode* node = nodes.front(); nodes.pop(); res[level].push_back(node-&gt;val); count++; if(node-&gt;left){ nodes.push(node-&gt;left); } if(node-&gt;right){ nodes.push(node-&gt;right); } } level++; } return res; } };","path":"2019/10/25/二叉树的遍历方法总结-md/","date":"10-25","excerpt":"","tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://haxisnake.github.io/tags/数据结构/"}]},{"title":"django文档学习笔记","text":"Django改变模型的三步走 编辑 models.py 文件，改变模型。 运行 python manage.py makemigrations 为模型的改变生成迁移文件。 运行 python manage.py migrate 来应用数据库迁移。","path":"2019/10/09/django文档学习笔记/","date":"10-09","excerpt":"","tags":[]},{"title":"后台开发核心技术与应用实践-读书笔记","text":"C++ 如何判断是指针数组还是数组指针？ 依据运算符的优先级： ()&gt;[]&gt;* 先与运算符结合的即为实际类别 int *p[n] 表示指针数组 int (*p)[n] 表示数组指针 long 类型在32位机器上只占4Byte，其他类型在32位机器和64位机器都是占同样的大小空间 union 中变量共用内存应以最长的为准 #include&lt;iostream&gt; using namespace std; union A{ int a[5J; char b; double c; } int main() { cout&lt;&lt;sizeof(A)&lt;&lt;endl; return O; } 程序的执行结果是： 24 因为按照double的8字节的 宏定义使用注意事项 当字符串中不只一个符号时，加上括号表现出优先级，如果是带数的宏定义，则要给宏体中的每个参数加上括号，并在整个宏体上再加一个括号 。 do while 与宏定义结合使用 可以宏定义代码块， 同时保证代码块语义不会被拆解。 #def 工ne Foo(x) do{\\ statement one;\\ statement two;\\ }while(0) //这里没有分号 条件编译 extern “C” 的使用 编译编译与链接 4个步骤： 预处理(Prepressing)、编译(Compilation)、汇编(Assembly)、链接(Linking) 预处理 经过预处理之后的.i文件不包含任何宏定义，因为所有的宏定义已经被展开，并且包含的文件也已经被插入到.i文件中。 编译 编译过程就是把预处理完的文件进行一系列的词法分析、语法分析、语义分析以及优化后产生相应的汇编代码文件，这个过程往往是整个程序构建的核心部分 链接 把每个源代码模块独立地编译，然后按照要将它们“组装”起来，这个组装模块的过程就是链接 。 链接的主要内容就是把各个模块之间相互引用的部分都处理好，使得各个模块之间能够正确的衔接。 静态链接 对函数库的链接是放在编译时期完成的是静态链接。所有相关的目标文件与牵涉到的函数库被链接合成一个可执行文件。 程序在运行时，与函数库再无瓜葛，因为所有需要的函数已复制到相关位置。 这些函数库被称为静态库，通常文件名为“ libxxx.a”的形式 。 动态链接 对一些库函数的链接载入推迟到程序运行时期（runtime），这就是动态链接库（ dynamic link library）技术。动态库文件名命名规范和静态库文件名命名规范类似，也是在动态库名增加前缀lib但其文件扩展名为. so。 -fPIC ：表示编译为位置独立的代码 。不用此选项的话编译后的代码是位置相关的，所以动态载入时是通过代码复制的方式来满足不同进程的需要，而不能达到真正代码段共享的目的。 -Lpath ：表示在 path 目录中搜索库文件，如－L. 则表示在当前目录。 -Ipath ：表示在 path 目录中搜索头文件。 -ltest ：编译器查找动态连接库时有隐含的命名规则，即在给出的名字前面加lib,后面加上.so来确定库的名称。 动态库的搜索路径搜索的先后顺序是： (1)编译目标代码时指定的动态库搜索路径； (2)环境变量 LD_LIBRARY_PATH 指定的动态库搜索路径； (3)配置文件/etc/ld.so.conf中指定的动态库搜索路径；即只需在在该文件中追加一行库所在的完整路径如 “/root/test/conf/lib”即可，然后ldconfig 是修改生效； (4)默认的动态库搜索路径/lib； (5)默认的动态库搜索路径/usr/lib。","path":"2019/08/12/后台开发核心技术与应用实践-读书笔记/","date":"08-12","excerpt":"","tags":[]},{"title":"化学品预测毒理学平台后台搭建笔记","text":"2019-07-01过程记录嗨~早上好呀！不知道今天你忙不忙哈哈。我来汇报一下这几天的工作，总共分为两点，有一点需要你抉择，另一点需要你来审核一下。第一点：我上周五晚上测试了新的chemwriter,但是可能是没有找到正确的配置方法，导致画图框架上面的按钮图标无法加载出来。由于我之前没怎么学过前端关于css和js的知识，所以要搞定这个框架的自动加载问题可能要很长一段时间，我目前的想法是先将现有的代码部署到那天扛回来的台式机上，然后上线之后再慢慢调试这个画图框架的加载问题，请问这样可以嘛？第二点：然后之前你不是说要把项目记录一下嘛。我这几天找到了一个感觉很好用的项目记录软件–trello.我这两天在上面简单做了一个看板，之后重建的cptp平台的工作都会按照顺序记录在这个看板上，希望可以方便进度汇报和以后的查看。但是需要你用邮箱注册一个trello的账号，然后我把你拉进看板里，这样你能更系统地看到我重建cptp的工作啦，而且如果遇到问题可以通过卡片的方式在trello进行讨论，方便以后整理。同时，我会将以前遇到的问题逐步整理到看板中，这样以后出现同样的问题可以用来做参考。嗯，今天的工作汇报主要是这些~祝生活愉快(^▽^)。emmm 写了这么多我打算发邮件了2333.2019年7月1日姜东 2019-06-18problem_061801_unsolved问题描述在用户点击账号激活邮件里的激活链接的时候，runserver命令的后台会出现如下报错信息： Traceback (most recent call last): File &quot;/usr/lib/python2.7/wsgiref/handlers.py&quot;, line 86, in run self.finish_response() File &quot;/usr/lib/python2.7/wsgiref/handlers.py&quot;, line 128, in finish_response self.write(data) File &quot;/usr/lib/python2.7/wsgiref/handlers.py&quot;, line 217, in write self._write(data) File &quot;/usr/lib/python2.7/socket.py&quot;, line 328, in write self.flush() File &quot;/usr/lib/python2.7/socket.py&quot;, line 307, in flush self._sock.sendall(view[write_offset:write_offset+buffer_size]) error: [Errno 32] Broken pipe [18/Jun/2019 23:40:43] &quot;GET /static/flat-ui/fonts/lato/lato-bold.woff HTTP/1.1&quot; 500 59 ---------------------------------------- Exception happened during processing of request from (&apos;10.9.16.128&apos;, 52341) Traceback (most recent call last): File &quot;/usr/lib/python2.7/SocketServer.py&quot;, line 596, in process_request_thread self.finish_request(request, client_address) File &quot;/usr/lib/python2.7/SocketServer.py&quot;, line 331, in finish_request self.RequestHandlerClass(request, client_address, self) File &quot;/home/jiangdong/.virtualenvs/ctws/local/lib/python2.7/site-packages/django/core/servers/basehttp.py&quot;, line 126, in __init__ super(WSGIRequestHandler, self).__init__(*args, **kwargs) File &quot;/usr/lib/python2.7/SocketServer.py&quot;, line 654, in __init__ self.finish() File &quot;/usr/lib/python2.7/SocketServer.py&quot;, line 713, in finish self.wfile.close() File &quot;/usr/lib/python2.7/socket.py&quot;, line 283, in close self.flush() File &quot;/usr/lib/python2.7/socket.py&quot;, line 307, in flush self._sock.sendall(view[write_offset:write_offset+buffer_size]) error: [Errno 32] Broken pipe 执行测试在active函数中进行了日志的输出，发现输出正常，无报错信息，但是依旧无法登录新用户。打算下一步测试更深层次的函数。 [19/Jun/2019 00:39:12] &quot;GET /accounts/register/complete/ HTTP/1.1&quot; 200 4037 active begin! ac key is:29714c0432eac0e00114b4a71d163597aa7ddb50 accout get! active over! [19/Jun/2019 00:44:20] &quot;GET /accounts/active/29714c0432eac0e00114b4a71d163597aa7ddb50/ HTTP/1.1&quot; 200 4019 解决方法(2019-06-28更新)原因是系统时间不对，导致后台误认为激活邮件已经过期，更改系统时间相关代码即可。 文件：utils/init.py def get_real_now(): #hack, only for mopac2012.exe expired # d = datetime.datetime.now() + datetime.timedelta(days=730) # modified by dong on 2019-6-20 # Reasons:at pervious code, mopac2012 may need the system time to be in its active time, # but now we use new mopac,so we need not to put a timdelta here d = datetime.datetime.now() s = time.mktime(d.timetuple()) now = datetime.datetime.fromtimestamp(s) chemistry_logger.info(&apos;------nws get real now %s&apos; % now) return now (2019-06-28更新结束) 2019-06-14Emm 今天效率略微低下 主要是阅读了用户注册部分的代码： 大致步骤为：注册-&gt;激活-&gt;登陆-&gt;登出 测试发现注册发送注册邮件功能是正常的，登陆登出功能也是正常的。如果直接在后台更改用户的active权限，新的用户也是可以登陆的。 主要问题是出现在用户激活的部分。这部分代码集中在Users/views.py的active函数以及users/models.py的RegistrationManager类和RegistrationProfile类 下一步打算设计一个测试情况，并在原代码中加入输出语句，详细定位出错位置。 2019-06-13好了！ Mopac找不到的原因是没有建立软连接至系统可执行文件的搜索目录，原先的方式是通过命令别名的形式调用的，建立之后就可以运行了,即解决了问题 problem_061201 计算任务可以成功！报告发送失败是因为邮箱的smtp服务没有开启，更换之后就可以了！现在可以发送报告！ 目前主要问题就剩下新用户没法验证登录，画图插件更新以及计算功能测试了！ 2019-06-12problem_061201_solved描述：最近编译并配置好了openbabel,能够正常运行，但是提交计算任务有出现了新的问题，提示找不到mopac 错误日志：celeryd 后台输出含有如下信息： /bin/sh: 1: mopac: not found 解决办法（2019-06-13更新）：Mopac找不到的原因是没有建立软连接至系统可执行文件的搜索目录，原先的方式是通过命令别名的形式调用的，在/usr/bin目录下建立软链接之后就可以运行了 （2019-06-13更新结束） 2019-06-07编译含有png输出支持的openbable 1.下载源码 https://sourceforge.net/projects/openbabel/files/openbabel/2.4.1/openbabel-2.4.1.tar.gz/download 2.安装额外支持的包 sudo apt install libboost-dev sudo apt-get install libcairo2-dev libxml2-dev zlib1g-dev libeigen2-dev libopenbabel-dev 3.安装对应版本编译器 sudo apt-get install g++-4.4 g++-4.4-multilib gcc-4.4 gcc-4.4-multilib 4.移除原先的openbabel sudo apt-get remove python-openbabel openbabel 4.解压源码 tar -xzvf openbabel-2.3.1.tar.gz 5.进行编译命令 cd openbabel-2.4.1/ mkdir build mkdir -p ~/opt/openbabel-install cd build cmake .. -DCMAKE_INSTALL_PREFIX=~/opt/openbabel-install -DPYTHON_BINDINGS=ON -DBUILD_GUI=OFF cmake .. -DCMAKE_INSTALL_PREFIX=~/opt/openbabel-install -DPYTHON_BINDINGS=ON在cmake中的CMAKE_CXX_FLAGS_RELEASE后面添加 –std=c++11 CMAKE_CXX_FLAGS_RELEASE:STRING=-O3 -DNDEBUG -std=c++11 issues: gcc g++ 版本不兼容 https://blog.csdn.net/yile0000/article/details/80105625 2019-06-06解决了problem_060501找到后台数据库管理界面（新发现）IP:port/admin problem_060601_unsolved描述： 用户无法注册登录的问题 出错日志： Exception Type: SMTPAuthenticationError Exception Value: (535, &apos;Error: authentication failed&apos;) 原因分析： 邮件服务没有通过认证，无法正常激活。 problem_060602_solved描述： openbabel问题不支持png图片生成 出错日志： [2019-06-06 00:10:20,183: ERROR/Worker-15] failed to submit task to prediction model Traceback (most recent call last): File &quot;/home/jiangdong/workspace/CTWS/ChemToolsWebService/chemistry/tasks.py&quot;, line 101, in calculateTask generate_mol_image(task) File &quot;/home/jiangdong/workspace/CTWS/ChemToolsWebService/chemistry/util.py&quot;, line 107, in generate_mol_image mol.draw(show=False, filename=ppath) File &quot;/usr/lib/python2.7/dist-packages/pybel.py&quot;, line 502, in draw raise ImportError(errormessage) ImportError: PNG output format not found. You should compile Open Babel with PNG support. See installation instructions for more information. 解决方法(2019-06-18更新):(编译含有png输出支持的openbable)[## 编译含有png输出支持的openbable] 详情请在本页搜索“编译含有png输出支持的openbable”或者点击链接（2019-06-13更新结束） problem_060603_unsolved问题描述： UnboundLocalError: local variable &apos;suite&apos; referenced before assignment(未解决) 出错日志： [2019-06-06 00:10:20,199: ERROR/MainProcess] Task chemistry.tasks.calculateTask[4898a17f-30b6-4ef7-a3f4-054b12dd719a] raised unexpected: UnboundLocalError(&quot;local variable &apos;suite&apos; referenced before assignment&quot;,) Traceback (most recent call last): File &quot;/home/jiangdong/.local/lib/python2.7/site-packages/celery/app/trace.py&quot;, line 240, in trace_task R = retval = fun(*args, **kwargs) File &quot;/home/jiangdong/.local/lib/python2.7/site-packages/celery/app/trace.py&quot;, line 437, in __protected_call__ return self.run(*args, **kwargs) File &quot;/home/jiangdong/workspace/CTWS/ChemToolsWebService/chemistry/tasks.py&quot;, line 138, in calculateTask suite.status_id = StatusCategory.objects.get(category=STATUS_FAILED) UnboundLocalError: local variable &apos;suite&apos; referenced before assignment 2019-06-05problem_060501_solveddjango报错提示： OperationalError: (1054, &quot;Unknown column &apos;local_search_id&apos; in &apos;field list&apos;&quot;) 出错日志： [2019-06-05 21:38:21,513: ERROR/Worker-15] failed to generate suite_task:1a8292d1-5820-4f01-8743-e131f889ecbd Traceback (most recent call last): File &quot;/home/jiangdong/workspace/CTWS/ChemToolsWebService/chemistry/util.py&quot;, line 451, in generate_calculate_task handle_smile_task(smile, model, sid, local_search_id) File &quot;/home/jiangdong/workspace/CTWS/ChemToolsWebService/chemistry/util.py&quot;, line 352, in handle_smile_task save_record(fpath, model, sid, ORIGIN_SMILE, smile, local_search_id) File &quot;/home/jiangdong/workspace/CTWS/ChemToolsWebService/chemistry/util.py&quot;, line 261, in save_record processed_f.save() 原因分析： 发现任务提交出错发生在chemistry/util.py的save_record函数中 底层错误为： OperationalError: (1054, &quot;Unknown column &apos;local_search_id&apos; in &apos;field list&apos;&quot;) 目前怀疑为数据库中缺少对应的项，正在根据代码核实涉及哪部分的数据库。 解决方法(2019-06-06更新) 进入数据库，运行 alter table chemistry_processedfile add column local_search_id INT(11) NULL; (2019-06-06更新结束) 2019-06-03画图框架需要手动刷新显示，故在html的渲染文件中添加一行温馨提示，添加位置在templates/newtask.html中{\\% include&amp;nbsp “widgets/chem-draw.html” \\%}之后。添加内容为 &lt;font style=”vertical-align: inherit;”&gt;若显示不正常右键绘图区域重新加载框架&lt;/font&gt; 2019-06-02任务列表界面无法访问，发现原因是生成的数据库中的对应表缺少一项，手动在数据库中添加即可。命令如下： mysql –uroot –p root use Chemistry; alter table chemistry_suitetask add column is_hide TINYINT(1) NOT NULL DEFAULT 0; alter table chemistry_singletask add column is_hide TINYINT(1) NOT NULL DEFAULT 0; 2019-06-01一些新的发现？ tools目录下的generate_models.py会根据data文件夹下的csv文件生成chemistry/calcore/matrix/下的py文件。 tools目录下的gen_check.py会根据data文件夹下的csv文件生成tools/data/check下的py文件。 tools/deploy目录下的import_local.py文件好像是导入啥东西的 没有细究。。。 tools/deploy目录下的build_production是用来配置生产环境相关目录的 主要是新建一些相关目录 以及安装对应的依赖包 和初始化数据库。 要安装supervisor sudo pip2 install supervisor python manage.py collectstatic 2019-05-28redis安装及配置redis安装配置django redis配置 apt-get install redis-server 2019-05-18使用不同的settings新建settings文件夹，将原先的settings.py配置成base.py,root_dir向上加一层目录copy dev.py至settings文件夹如下形式启动 python2 manage.py runserver –settings=./settings.settings_dev.py 2019-05-15CPTP平台进展记录 图一 图二 进展说明经过各种依赖库的安装及相关框架的配置，现在已能够在本地访问平台首页，相关测试结果如下： 首页、平台远景、软件帮助这三个页面的内容目前都是一样的…见图一。 图二是“预测计算-新建计算”的页面，但目前还不能提交计算原因可能是Dragon的license还没有配置上，等license配置结束应该就可以正常计算 “预测计算-任务列表”页面访问会出错，估计原因有两种：一是没有预测任务，所以访问出错。二是网站本身链接不存在或者缺少三方包导致访问出错。 分子绘图界面目前显示有些问题，可能是先关文件在源仓库的缺失导致的，需要进一步分析解决。 文件上传功能需要后续继续测试。 接下来的工作 找一台在机房的节点重新部署平台。 等待官网发放license，继续测试计算功能。 阅读相关功能模块源码，找出进展3,4中问题的具体原因。 根据提供的资料，完善平台的首页，平台远景以及软件帮助的静态界面。 2019-05-10今天的思路是采用虚拟环境virtualenv在16.04上使用python2.7配置环境。 添加32位库的支持 改为 sudo apt-get install g++-multilib 2019-04-23下载了bootstrap 目前还不知道有啥用 安装Django官网链接 更改了fail_n*n.png的文件名字，使得仓库能够被完整下载 更新了requirement文件,解决了python三方包的依赖问题但是没有测试三方包能否在现有代码中运行 错误1 描述： -bash: ./tools/build_env.sh: /bin/bash^M: bad interpreter: No such file or directory 解决办法 链接 错误2 描述： 找不到virtualenv: command not found 解决方法 安装virtualenv pip3 install –user virtualenv 总结：现在这份仓库的代码使用的Django-1.6.3和python2的版本，可以说非常的古老，如果要方便后续开发，最好是能转成Django-2.2和python3.5不过这个工作量很多，因为Django2.x相比1.x版本是全新的一个版本，而且只能支持python3，需要慎重考虑。","path":"2019/06/06/化学品预测毒理学平台后台搭建笔记/","date":"06-06","excerpt":"","tags":[{"name":"环境搭建","slug":"环境搭建","permalink":"https://haxisnake.github.io/tags/环境搭建/"},{"name":"Django","slug":"Django","permalink":"https://haxisnake.github.io/tags/Django/"}]},{"title":"设置linux开机启动脚本自动联网认证","text":"由于学校的网络需要认证上网,每次服务器上网都用个人账号认证，因此需要配置下开机启动脚本使其自动上网。(其实就是没钱惹的祸) 一、上网认证的脚本先安装依赖:sudo apt-get install python-pipsudo pip3 install schedulesudo pip3 install argparse task.py： import schedule import time from urllib.parse import quote, unquote import requests import argparse def job(User,Pass): base_url = &apos;http://auth.dlut.edu.cn&apos; try: resp = requests.get(base_url) print(&quot;conneting...&quot;) except Exception: #print(&quot;Already connected...&quot;) return query = resp.text[resp.text.find(&apos;wlanuserip&apos;):resp.text.find(&apos;&lt;/script&gt;&apos;)] query_str = quote(quote(query)) url = base_url + &apos;/eportal/InterFace.do?method=login&apos; data = { &apos;userId&apos;: User, # username 1 &apos;password&apos;: Pass, # password &apos;service&apos;: &apos;&apos;, # empty &apos;queryString&apos;: query_str, &apos;operatorPwd&apos;: &apos;&apos;, # empty &apos;operatorUserId&apos;: &apos;&apos;, # empty &apos;validcode&apos;: &apos;&apos;, # empty } headers = {&apos;Content-Type&apos;: &apos;application/x-www-form-urlencoded; charset=UTF-8&apos;} resp = requests.post(url, data, headers=headers) print(resp.status_code) print(resp.text) parser = argparse.ArgumentParser(description=&apos;connect to dlut&apos;) parser.add_argument(&apos;-u&apos;,type=str, help=&apos;user name&apos;) parser.add_argument(&apos;-p&apos;,type=str, help=&apos;user name&apos;) args = parser.parse_args() User = args.u Pass = args.p job(User, Pass) schedule.every(300).minutes.do(job,User,Pass) while True: schedule.run_pending() time.sleep(300) 其主要作用是进行认证链接,命令行调用格式为: python3 task.py -u username -p passwd username是认证用户名，passwd是对应密码 二、编写bash脚本调用登陆脚本connect.sh: #!/bin/bash python3 /home/sie/netset/task.py -u username -p passwd &amp; 添加可执行权限: chmod +x connect.sh 将connect.sh和task.py都放到同一目录下 设为path_to_sp 三、在/etc/rc.local里添加开机启动脚本命令 配置rc-local.service服务使其能够执行开机启动脚本 参考教程 root权限创建/etc/rc.local文件并写入开机启动的脚本 #!/bin/sh -e # # rc.local # # This script is executed at the end of each multiuser runlevel. # Make sure that the script will &quot;exit 0&quot; on success or any other # value on error. # # In order to enable or disable this script just change the execution # bits. # # By default this script does nothing. su -s /bin/sh sie -c&quot;path_to_sp/connect.sh&quot; exit 0 其中path_to_sp为connect.sh和task.py的目录 至此开机启动配置结束。 以前一直想搞定开机启动脚本的事情，但是总不得其要点，特此记录，以后还要多多了解原理才是。","path":"2019/05/29/设置linux开机启动脚本自动联网认证/","date":"05-29","excerpt":"","tags":[{"name":"服务器维护","slug":"服务器维护","permalink":"https://haxisnake.github.io/tags/服务器维护/"}]},{"title":"服务器环境搭建","text":"ubuntu18.04-servercuda10.1cudann7.5.0 安装显卡驱动 linux查看显卡型号 lshw -numeric -C display 下载nvidia官方驱动 官网链接 bios禁用禁用secure boot 禁用nouveau 打开文件 sudo vim /etc/modprobe.d/blacklist.conf 在最后一行添加: blacklist nouveau 执行如下命令生效 sudo update-initramfs -u 重启 使用命令查看nouveau有没有运行 lsmod | grep nouveau # 没输出代表禁用生效 停止可视化界面 sudo telinit 3 安装驱动 先添加可执行权限 sudo chmod a+x filename.run 执行安装： sudo ./filename.run -no-opengl-files -noopengl-files这个参数一定要加，否则会循环登录 安装CUDA10.1 下载cuda10.1安装文件 官网链接 运行安装 执行安装文件进行安装，同nvidia驱动的执行方式。 注意此时不需要选择安装驱动。驱动版本要注意跟cuda版本相对应。 安装cudann请见官网安装教程","path":"2019/05/07/服务器环境搭建ubuntu18-04-server-cuda10-1-cudann/","date":"05-07","excerpt":"","tags":[]},{"title":"OpenPose环境搭建笔记","text":"OpenPose环境搭建笔记编译caffe recipe for target ‘.build_release/src/caffe/proto/caffe.pb.o’ failed 参考教程：https://blog.csdn.net/w5688414/article/details/79478695 ./include/caffe/util/hdf5.hpp:6:18: fatal error: hdf5.h: No such file or directory 解决办法：在Makefile.config找到以下行并添加蓝色部分 INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-Linux-gnu/hdf5/serial 3.1 如果仍然提示找不到lhdf5和lhdf5_hl(这是因为ubuntu16.04的文件包含位置发生了变化，尤其是需要用到的hdf5的位置，所以需要更改这一路径)选自caffe —找不到lhdf5_hl和lhdf5的错误 解决办法：然后根据情况执行下面两句： cd /usr/lib/x86_64-linux-gnu sudo ln -s libhdf5_serial.so.10.1.0 libhdf5.so sudo ln -s libhdf5_serial_hl.so.10.0.2 libhdf5_hl.so https://github.com/BVLC/caffe/issues/6359 /usr/include/c++/5/typeinfo:39:37: error: expected ‘}’ before end of line/usr/include/c++/5/typeinfo:39:37: error: expected unqualified-id before end of line/usr/include/c++/5/typeinfo:39:37: error: expected ‘}’ before end of line/usr/include/c++/5/typeinfo:39:37: error: expected ‘}’ before end of line/usr/include/c++/5/typeinfo:39:37: error: expected ‘}’ before end of line/usr/include/c++/5/typeinfo:39:37: error: expected declaration before end of lineMakefile:588: recipe for target ‘.build_release/src/caffe/proto/caffe.pb.o’ failedmake: *** [.build_release/src/caffe/proto/caffe.pb.o] Error 1 CXXFLAGS += -pthread -fPIC $(COMMON_FLAGS) $(WARNINGS) -std=c++11NVCCFLAGS += -D_FORCE_INLINES -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS) -std=c++11LINKFLAGS += -pthread -fPIC $(COMMON_FLAGS) $(WARNINGS) -std=c++11 Unsupported gpu architecture ‘compute_20’ 注释Makefile.config 中 : # CUDA architecture setting: going with all of them. # For CUDA &lt; 6.0, comment the *_50 through *_61 lines for compatibility. # For CUDA &lt; 8.0, comment the *_60 and *_61 lines for compatibility. # For CUDA &gt;= 9.0, comment the *_20 and *_21 lines for compatibility. CUDA_ARCH := -gencode arch=compute_30,code=sm_30 \\ -gencode arch=compute_35,code=sm_35 \\ -gencode arch=compute_50,code=sm_50 \\ -gencode arch=compute_52,code=sm_52 \\ -gencode arch=compute_60,code=sm_60 \\ -gencode arch=compute_61,code=sm_61 \\ -gencode arch=compute_61,code=compute_61 leveldbhttps://blog.csdn.net/oeljeklaus/article/details/78802922 https://blog.csdn.net/fogxcg/article/details/75332146 build opencv3.4 cmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local -D PYTHON3_EXECUTABLE=/usr/bin/python3 -D PYTHON_INCLUDE_DIR=/usr/include/python3 -D PYTHON_INCLUDE_DIR2=/usr/include/x86_64-linux-gnu/python3.5m -D PYTHON_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.5m.so -D PYTHON3_NUMPY_INCLUDE_DIRS=/usr/lib/python3/dist-packages/numpy/core/include/ levelDB出错 https://blog.csdn.net/jyl1999xxxx/article/details/80583465 glog 和 gflags 的安装https://www.cnblogs.com/burningTheStar/p/6986048.html-fPIChttps://github.com/BVLC/caffe/issues/2171 make runtest .build_release/tools/caffe: error while loading shared libraries: libopencv_imgcodecs.so.3.4: cannot open shared object file: No such file or directoryMakefile:542: recipe for target ‘runtest’ failed make runtest https://blog.csdn.net/wonengguwozai/article/details/52724409 编译openpose cuda结构不共存 Unsupported gpu architecture ‘compute_xx’ 在cmake-gui 中选择 CUDA_ARCH 为mannul 然后再删掉其中不符合的结构 g++: error trying to exec ‘cc1plus’: execvp: 没有那个文件或目录 gcc g++ 版本不兼容 https://blog.csdn.net/yile0000/article/details/80105625 nvidia驱动 https://blog.csdn.net/wf19930209/article/details/81877822 sudo service lightdm stop gflags.cc is being linked both statically and dynamically https://github.com/google/glog/issues/53 修改CmakeCache.txt中的GFLAGS_LIBRARY:FILEPATH=/usr/local/lib/libgflags.a改为：GFLAGS_LIBRARY:FILEPATH=/usr/local/lib/libgflags.so然后重新编译 [libprotobuf ERROR google/protobuf/message_lite.cc:123] Can’t parse message of type “caffe.NetParameter” because it is missing required fields: layer[0].clip_param.min, layer[0].clip_param.max 要用openpose自带的caffe库 选择openpose编译caffe时选项可以在3rdparty/caffe中设置编译参数","path":"2019/04/09/OpenPose环境搭建笔记/","date":"04-09","excerpt":"","tags":[]},{"title":"智能教室项目记录","text":"问题：放入新的数据时，训练的loss输出值总是nan 尝试： 调小学习率 未解决 2019-3-25 现在发现数据的标签中有nan值，怀疑是数据集问题，打算对自己的数据集进行检查 经过检查后发现，在从cvat的标签文件转为voc格式的标签文件时，边框的长宽颠倒导致数据出错。 2019年4月1日经过几天的训练，SSD网络在我们自己构造的数据上已经有了很好的表现，能在测试集上达到90.09的MAP，但是发现相比于原先在VOC上的网络模型，新训练出来的模型对于小目标的识别有了较大改善，但是对于大目标的识别率有所下降，因此今天写了从VOC中提取特定种类图片的脚本，打算将其他数据集中跟人体有关的数据纳入到新的数据集中，削减教室中图片数量，提升数据集的多样性。","path":"2019/03/26/智能教室项目记录/","date":"03-26","excerpt":"","tags":[]},{"title":"docker无法启动问题调试","text":"Job for docker.service failed. See &quot;systemctl status docker.service&quot; and &quot;journalctl -xe&quot; for details. Error starting daemon: error while opening volume store metadata database: timeout ps axf | grep docker | grep -v grep | awk &apos;{print &quot;kill -9 &quot; $1}&apos; | sudo sh sudo systemctl start docker","path":"2019/02/18/docker无法启动问题调试/","date":"02-18","excerpt":"","tags":[]},{"title":"C++ vector size()与有符号数比较要注意的问题","text":"C++ vector size()与有符号数比较要注意的问题今天在刷题时要写一个循环体，为了保证能包括初始情况，其中一个循环变量要从j=-1开始计数，但是导致终止条件j&lt;num.size(),一直为false,后经过调试发现是因为vector的size()方法返回的是无符号整形，因此与有符号数进行比较时要显式的进行一次类型转换。即j&lt;(int)num.size(),即要注意下面代码中第一个循环体结束语句的写法。 12345678910111213141516171819202122232425class Solution &#123;public: int minSubArrayLen(int s, vector&lt;int&gt;&amp; nums) &#123; if(0==nums.size()) return 0; int sum=0; int subarraylen=nums.size()+1; for(int i=0,j=-1;(i&lt;nums.size()) &amp;&amp; (j&lt;(int)nums.size());)&#123; if(sum&lt;s)&#123; sum+=nums[++j]; &#125;else&#123; if(i==j)&#123; return 1; &#125; subarraylen=(j-i+1)&lt;subarraylen?(j-i+1):subarraylen; sum-=nums[i++]; &#125; &#125; if(subarraylen!=nums.size()+1)&#123; return subarraylen; &#125;else&#123; return 0; &#125; &#125;&#125;;","path":"2019/01/14/C-vector-size-与有符号数比较要注意的问题/","date":"01-14","excerpt":"","tags":[{"name":"bug","slug":"bug","permalink":"https://haxisnake.github.io/tags/bug/"},{"name":"c++","slug":"c","permalink":"https://haxisnake.github.io/tags/c/"}]},{"title":"使用python搭建小型搜索引擎","text":"项目代码链接 一、目标为准备信息检索课程的期末大作业，因此我使用python搭建了一个小型的搜索引擎，其功能是检索大工新闻网的新闻。 二、原理和工具简介2.1 原理该搜索引擎的原理是采用scrapy对大工新闻网进行爬虫，提取出文字新闻，并将新闻内容存入数据库A，再利用Django框架搭建一个搜索服务器，在服务器上部署Haystack+Whoosh搜索引擎，使用jieba分词工具来进行中文分词和停用词过滤。通过搜索引擎工具建立索引文件后，在前端完成用户交互界面，实现一个完整的小型搜索引擎。 2.2 工具简介 Scrapy Python开发的一个快速、高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据。Scrapy用途广泛，可以用于数据挖掘、监测和自动化测试。 在本项目中用来爬取网站数据。 Django Django是一个开放源代码的Web应用框架，由Python写成。采用了MVC的框架模式，即模型M，视图V和控制器C。 在本项目用来做搜索服务器的框架。 Haystack+Whoosh Haystack是一个Django上的应用，可以用于整合搜索引擎，它只依赖于它自身的代码，利用它可以切换不同的搜索引擎工具。Whoosh是一个索引文本和搜索文本的类库，它可以提供搜索文本的服务。 在本项目中使用Haystack将Whoosh部署到Django服务器作为搜索引擎后端。 Jieba Jieba是一个python实现的分词库，对中文有着很强大的分词能力。 在本项目用于对新闻进行中文分词和停用词过滤。 三、开发环境和运行环境3.1 开发环境 win 10 python 3.6.5 scrapy 1.5.1 安装教程 Django 2.1.3 安装教程 Haystack+Whoosh 配置教程 Jieba 0.39 配置教程 3.2 运行环境同开发环境 四、系统模块4.1 网络爬虫模块定义用于Scrapy爬虫的数据类型，包括链接、标题和文章内容:1234class NewsItem(scrapy.Item): url = scrapy.Field() title = scrapy.Field() content = scrapy.Field() 编写爬虫策略:爬虫策略的制定依据于网页源代码的链接形式，由于要爬取的是文字类新闻，所以要跟进与文字类新闻的链接。对于具体的新闻页利用回调函数爬取其链接、标题和内容。而对于新闻列表页，需要跟进下一页的链接。具体规则代码如下: 12345678910111213141516171819202122class NewsSpider(CrawlSpider): print(\"news spider starting\") name = 'news' allowed_domains = ['news.dlut.edu.cn'] start_urls = ['http://news.dlut.edu.cn/'] rules = ( # 对于新闻页链接进行跟进 Rule(LinkExtractor(allow=(\"xw/[a-z]+.htm\"))), # 对于详细新闻页利用parse_item回调函数进行内容爬取 Rule(LinkExtractor(allow=(\"info/\\d&#123;4,&#125;/\\d&#123;3,&#125;\\.htm\")),callback=\"parse_item\"), # 对于新闻列表中的下一页链接进行跟进 Rule(LinkExtractor(allow=(\"\\d&#123;1,&#125;.htm\"),restrict_xpaths=\"//a[@class='Next']\")), ) def parse_item(self, response): self.log(\"Hi, this is a new page! %s\"% response.url) item = NewsItem() item['title'] = response.xpath('/html/head/title/text()').extract()[0] item['url'] = response.url item['content']=response.xpath(\"//div[@class='cont-detail fs-small']/p/text()\").extract() yield item 使用pipline机制将数据保存至数据库当中1234567891011121314151617181920212223242526272829class SpiderprojectPipeline(object): def process_item(self, item, spider): if spider.name == 'news': conn = sqlite3.connect('db.sqlite3') cursor = conn.cursor() title = item['title'] url = item['url'] content_tmp = item['content'] content=\"\" for p in content_tmp: content+=p.strip() sql_search = 'select arturl from search_article where arturl==\"%s\"' % (url) sql = 'insert into articles_article(title, content, arturl) values(\"%s\", \"%s\", \"%s\")'%(title, content, url) try: #如果当前数据库中不存在该条新闻，则将新闻保存至数据库当中 cursor.execute(sql_search) result_search = cursor.fetchone() if result_search is None or result_search[0].strip()=='': cursor.execute(sql) result=cursor.fetchone() conn.commit() cursor.execute(sql) result=cursor.fetchone() conn.commit() except Exception as e: print(\"&gt;&gt;&gt; catch exception !\") print(e) conn.rollback() return item 4.2 搜索模块在要进行搜索的应用的models.py文件中建立model类用来表示要进行搜索的新闻文章 1234class Article(models.Model): title = models.CharField(max_length=50) arturl = models.CharField(max_length=200) content = models.CharField(max_length=1000) 同时使用django命令python manage.py makemigrations和python manage.py migrate生成数据库文件，并用爬虫得到的数据库替换生成的数据库。 在django框架中配置Haystack+Whoosh来引入搜索模块 123456789101112# 配置搜索引擎后端HAYSTACK_CONNECTIONS=&#123; 'default':&#123; 'ENGINE': 'articles.whoosh_cn_backend.WhooshEngine', # 索引文件路径 'PATH': os.path.join(BASE_DIR, 'whoosh_index'), # 在项目目录下创建文件夹 whoosh_index &#125;&#125;# 当添加、修改、删除数据时，自动生成索引HAYSTACK_SIGNAL_PROCESSOR = 'haystack.signals.RealtimeSignalProcessor'# 每页显示十条搜索结果HAYSTACK_SEARCH_RESULTS_PER_PAGE = 10 在要进行搜索的应用的目录下建立search_indexes.py文件 123456789101112from haystack import indexesfrom articles.models import Articleclass ArticleIndex(indexes.SearchIndex, indexes.Indexable): #类名必须为需要检索的Model_name+Index，这里需要检索Article，所以创建ArticleIndex text = indexes.CharField(document=True, use_template=True) #创建一个text字段 def get_model(self): #重载get_model方法，必须要有！ return Article def index_queryset(self, using=None): #重载index_..函数 \"\"\"Used when the entire index for model is updated.\"\"\" return self.get_model().objects.all() 在articles\\templates\\search\\indexes\\articles\\下建立article_text.txt文件确定搜索内容 123&#123;&#123; object.title &#125;&#125;&#123;&#123; object.content &#125;&#125;&#123;&#123; object.url &#125;&#125; 4.2 预处理模块使用jieba来进行中文分词，需要在whoosh_cn_backend文件中替换StemmingAnalyzer为ChineseAnalyzer 同时引入停用词表，配置ChineseAnalyzer使其支持停用词过滤 1234567891011121314151617181920212223242526import jiebaimport reimport os# 导入停用词过滤表stop_file_dir=os.path.dirname(os.path.dirname(os.path.abspath(__file__)))STOP_WORDS = frozenset([line.strip() for line in open(os.path.join(stop_file_dir, 'stop.txt'),'r',encoding='gbk').readlines()])accepted_chars = re.compile(r\"[\\u4E00-\\u9FD5]+\")class ChineseTokenizer(Tokenizer): def __call__(self, text, **kargs): words = jieba.tokenize(text, mode=\"search\") token = Token() for (w, start_pos, stop_pos) in words: if not accepted_chars.match(w) and len(w) &lt;= 1: continue token.original = token.text = w token.pos = start_pos token.startchar = start_pos token.endchar = stop_pos yield token def ChineseAnalyzer(stoplist=STOP_WORDS, minsize=1, stemfn=stem, cachesize=50000): return (ChineseTokenizer() | LowercaseFilter() | StopFilter(stoplist=stoplist, minsize=minsize) | StemFilter(stemfn=stemfn, ignore=None, cachesize=cachesize)) 配置完成后使用python manage.py rebuild_index建立搜索索引 4.4 交互模块搜索首页html关键代码： 12345&lt;form method='get' action=\"/search/\" target=\"_blank\"&gt; &lt;input type=\"text\" name=\"q\"&gt; &lt;br&gt; &lt;input type=\"submit\" value=\"查询\"&gt;&lt;/form&gt; 首页如下图所示： 查询结果页html关键代码： 12345678910111213141516171819&#123;% load highlight %&#125;&lt;h3&gt;搜索&amp;nbsp;&lt;b&gt;&#123;&#123;query&#125;&#125;&lt;/b&gt;&amp;nbsp;结果如下：&lt;/h3&gt;&lt;ul&gt;&#123;%for item in page%&#125; &lt;li&gt;&#123;&#123;item.object.title|safe&#125;&#125;&lt;/li&gt; &lt;p&gt;&#123;% highlight item.object.content with query %&#125;&lt;/p&gt; &lt;a href=&quot;&#123;&#123;item.object.arturl&#125;&#125;&quot;&gt;&#123;&#123;item.object.arturl&#125;&#125;&lt;/a&gt;&#123;%empty%&#125; &lt;li&gt;啥也没找到&lt;/li&gt;&#123;%endfor%&#125;&lt;/ul&gt;&lt;hr&gt;&#123;%for pindex in page.paginator.page_range%&#125; &#123;%if pindex == page.number%&#125; &#123;&#123;pindex&#125;&#125;&amp;nbsp;&amp;nbsp; &#123;%else%&#125; &lt;a href=&quot;?q=&#123;&#123;query&#125;&#125;&amp;amp;page=&#123;&#123;pindex&#125;&#125;&quot;&gt;&#123;&#123;pindex&#125;&#125;&lt;/a&gt;&amp;nbsp;&amp;nbsp; &#123;%endif%&#125;&#123;%endfor%&#125; 其中使用 12&#123;% load highlight %&#125;&lt;p&gt;&#123;% highlight item.object.content with query %&#125;&lt;/p&gt; 进行搜索结果的高亮显示 最终搜索页面如下图所示： 五、项目代码代码链接","path":"2018/12/31/使用python搭建小型搜索引擎/","date":"12-31","excerpt":"","tags":[{"name":"Python","slug":"Python","permalink":"https://haxisnake.github.io/tags/Python/"},{"name":"Scrapy","slug":"Scrapy","permalink":"https://haxisnake.github.io/tags/Scrapy/"},{"name":"Django","slug":"Django","permalink":"https://haxisnake.github.io/tags/Django/"},{"name":"Haystack","slug":"Haystack","permalink":"https://haxisnake.github.io/tags/Haystack/"},{"name":"Whoosh","slug":"Whoosh","permalink":"https://haxisnake.github.io/tags/Whoosh/"},{"name":"Jieba","slug":"Jieba","permalink":"https://haxisnake.github.io/tags/Jieba/"}]},{"title":"树莓派3B——turtlebot3——ROS开发环境搭建问题记录","text":"由于一个比赛项目需要在ROS上做开发，但是按照网上教程搭建开发环境出现了一些问题，因此在此做简单整理，本笔记的开发环境如下： 硬件环境：turtlebot3 burger(用的其自带的树莓派为raspberry3B) 树莓派系统版本：ubuntu-mate-16.04.2-desktop-armhf PC系统版本： ubuntu-16.04.3-desktop-amd64 教程参考： https://www.ncnynl.com/archives/201702/1392.html 问题记录问题一问题描述：wget 安装脚本时验证出错导致脚本无法下载 解决方法：在wget命令后加上–no-check-certificate选项即可 问题二问题描述：git clone 出现CAfile: /etc/ssl/certs/ca-certificates.crt CRLfile: none错误 解决方式：运行 export GIT_SSL_NO_VERIFY=1 问题三问题描述：安装turtlebot依赖包之后找不到catkin_make命令 解决方式：重新执行 source /opt/ros/kinetic/setup.sh 问题四问题描述：cakin_make时找不到interactive_maker模块 解决方式：修改安装脚本，使其安装desktop_full版本 问题五问题描述：checksum error when launching turtlebot3_bringup 解决方式：更新OpenCR固件至最新版与ROS版本相匹配","path":"2018/07/18/树莓派3B-turtlebot3ros开发环境搭建问题记录/","date":"07-18","excerpt":"","tags":[{"name":"环境搭建","slug":"环境搭建","permalink":"https://haxisnake.github.io/tags/环境搭建/"},{"name":"raspberry3B","slug":"raspberry3B","permalink":"https://haxisnake.github.io/tags/raspberry3B/"},{"name":"ROS","slug":"ROS","permalink":"https://haxisnake.github.io/tags/ROS/"},{"name":"turtlebot3","slug":"turtlebot3","permalink":"https://haxisnake.github.io/tags/turtlebot3/"}]},{"title":"opencv3-ubuntu16.04-install","text":"123456789101112131415161718sudo apt-get install cmakesudo apt-get install python3-dev python3-numpysudo apt-get install gcc g++sudo apt-get install libgtk2.0-devsudo apt-get install libv4l-devsudo apt-get install libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-devsudo apt-get install sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev liblapacke-devsudo apt-get install libxvidcore-dev libx264-dev sudo apt-get install libatlas-base-dev gfortransudo apt-get install ffmpeg sudo apt-get install gitgit clone https://github.com/opencv/opencv.gitcmake dir/of/opencv/sourcesudo make -j4 sudo make install","path":"2018/07/17/opencv3-ubuntu16-04-install/","date":"07-17","excerpt":"","tags":[{"name":"环境搭建","slug":"环境搭建","permalink":"https://haxisnake.github.io/tags/环境搭建/"},{"name":"opencv3","slug":"opencv3","permalink":"https://haxisnake.github.io/tags/opencv3/"}]},{"title":"树莓派3B+编译安装opencv3","text":"一、更新源12mv sources.list /etc/apt/sources.list mv raspi.list /etc/apt/sources.list.d/raspi.list 更新源的配置，注意文件存放的位置文件sources.list和raspi.list具体内容如下 sources.list文件: deb http://mirrors.ustc.edu.cn/raspbian/raspbian/ stretch main contrib non-free rpi deb http://mirrors.aliyun.com/raspbian/raspbian/ stretch main contrib non-free rpi deb http://mirrors.tuna.tsinghua.edu.cn/raspbian/raspbian/ stretch main contrib non-free rpi deb http://mirrors.neusoft.edu.cn/raspbian/raspbian/ stretch main contrib non-free rpi raspi.list文件:1234deb http://mirrors.ustc.edu.cn/raspbian/raspbian/ stretch main uideb http://mirrors.aliyun.com/raspbian/raspbian/ stretch main uideb http://mirrors.tuna.tsinghua.edu.cn/raspbian/raspbian/ stretch main uideb http://mirrors.neusoft.edu.cn/raspbian/raspbian/ stretch main ui 在终端执行更新命令:12sudo apt-get updatesudo apt-get upgrade 二、安装依赖包123456789sudo apt-get install build-essential cmake git pkg-config sudo apt-get install libjpeg8-dev sudo apt-get install libtiff5-dev sudo apt-get install libjasper-dev sudo apt-get install libpng12-devsudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libv4l-devsudo apt-get install libgtk2.0-devsudo apt-get install libatlas-base-dev gfortran 注意：降级安装有些安装包依赖的版本低需要降级安装，如下，对depends后面的进行降级安装1sudo aptitude install xxxx 三、下载源码1git clone https://github.com/opencv/opencv.git 四、编译1234cmake dir/of/opencv/sourcesudo make -j4 sudo make installsudo ldconfig","path":"2018/07/17/树莓派3B-编译安装opencv3/","date":"07-17","excerpt":"","tags":[{"name":"环境搭建","slug":"环境搭建","permalink":"https://haxisnake.github.io/tags/环境搭建/"},{"name":"opencv3","slug":"opencv3","permalink":"https://haxisnake.github.io/tags/opencv3/"},{"name":"raspberry3B+","slug":"raspberry3B","permalink":"https://haxisnake.github.io/tags/raspberry3B/"}]}]}